{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "secretkey = userdata.get('OPENAI')\n",
        "# Set the OpenAI API key as an environment variable\n",
        "os.environ['OPENAI_API_KEY'] = secretkey\n",
        "!pip install streamlit yfinance openai numpy\n",
        "# install curl and wget\n",
        "!apt-get install -y curl\n",
        "#!apt-get install -y wget"
      ],
      "metadata": {
        "id": "QUt9v_AGav-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "03bcdee0-90d6-4bd2-e6bf-79fa77f21efe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.5.0)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.7)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2025.11.12)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.29.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.81.0-1ubuntu1.21).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://loca.lt/mytunnelpassword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euhdY8GgWz8u",
        "outputId": "225db47e-f702-476d-a2d4-2ff5de4ef0fb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.26.182.67"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10b3cae6",
        "outputId": "14e4234f-7065-4e2b-cd3d-632d854eeb0f",
        "collapsed": true
      },
      "source": [
        "# Set the OpenAI API key as an environment variable before running the Streamlit app\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "openai_secret_key = userdata.get('OPENAI')\n",
        "os.environ['OPENAI_API_KEY'] = openai_secret_key\n",
        "\n",
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0Kyour url is: https://strong-frogs-yell.loca.lt\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.26.182.67:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2025-12-02 06:39:08.064 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:45:27.576 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:49:17.119 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:49:37.690 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:49:38.056 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:49:41.529 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:49:41.797 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:54:36.381 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:54:38.329 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:54:39.747 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "/content/app.py:2122: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"time\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
            "2025-12-02 06:54:48.704 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:54:48.709 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:54:52.366 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:54:52.372 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:54:52.920 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:54:52.924 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:54:53.753 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:54:53.760 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:54:55.718 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:54:55.724 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:54:56.879 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:54:56.887 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:54:59.025 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:54:59.031 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:55:04.549 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:55:04.557 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:55:24.364 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:55:24.370 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:55:50.286 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:55:50.292 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "/content/app.py:2277: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"time\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
            "2025-12-02 06:56:03.007 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:56:03.016 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:56:03.022 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:56:07.941 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:56:07.952 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:56:07.958 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:56:14.252 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:56:14.259 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:56:14.268 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "/content/app.py:2277: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"time\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
            "2025-12-02 06:56:54.839 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:56:54.846 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:56:54.852 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:56:59.898 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:56:59.905 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:57:01.337 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:57:01.344 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "/content/app.py:2277: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"time\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
            "2025-12-02 06:57:23.101 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:57:23.109 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:57:23.115 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:57:49.281 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:57:49.289 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:57:49.295 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "/content/app.py:2277: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"time\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
            "2025-12-02 06:57:56.287 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:57:56.294 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:58:04.628 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:58:04.635 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "/content/app.py:2004: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"time\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
            "2025-12-02 06:58:36.016 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:58:36.024 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:58:49.483 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:58:49.491 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:58:50.411 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:58:50.418 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:58:57.996 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:58:58.005 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "/content/app.py:2004: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"time\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
            "2025-12-02 06:59:10.057 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:59:10.064 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:59:33.086 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 06:59:33.094 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:00:24.950 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:00:24.958 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:00:26.433 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:00:26.440 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "/content/app.py:2122: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"time\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
            "2025-12-02 07:00:34.036 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:00:34.044 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:00:43.073 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:00:43.080 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "/content/app.py:2122: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"time\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
            "2025-12-02 07:00:50.292 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:00:50.301 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:01:00.215 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:01:00.224 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:01:02.448 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:01:02.455 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:01:24.540 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:01:24.547 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "/content/app.py:2277: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"time\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
            "2025-12-02 07:01:49.005 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:01:49.014 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:01:49.023 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "/content/app.py:2277: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"time\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
            "2025-12-02 07:02:20.752 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:02:20.761 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:02:20.769 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "/content/app.py:2004: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"time\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
            "2025-12-02 07:03:21.525 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:03:21.533 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 07:03:21.540 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0899025f",
        "outputId": "99670d63-5dfb-4f26-ba9b-629f4bea0a33"
      },
      "source": [
        "%%writefile app.py\n",
        "\"\"\"\n",
        "MarketWhisper AI Agent App (Prompt Engineering CS4680 Final Project)\n",
        "=================================================\n",
        "\n",
        "This is the *full* project version of MarketWhisper. It is designed to:\n",
        "\n",
        "- Fetch **live market data** (via `yfinance`)\n",
        "- Pull **fresh external context** (via Reddit search + optional NewsAPI)\n",
        "- Feed that external context into the LLM so it can reason about **Q3 earnings,\n",
        "  current news, social buzz**, etc. despite its training cutoff\n",
        "- Act as a multi-domain **AI Agent**:\n",
        "    * Finance Agent (plans + executes finance-related tasks)\n",
        "    * File System Agent (plans + executes file operations safely)\n",
        "    * General Chat Agent (optionally finance-aware, using live context)\n",
        "- Provide a full **GUI** (Streamlit) + logging and safety checks\n",
        "\n",
        "Core Project Requirements Mapping\n",
        "---------------------------------\n",
        "LLM Integration Module\n",
        "- Uses OpenAI Python SDK (client.chat.completions.create)\n",
        "- Centralized helper with retry + simple backoff for rate limits\n",
        "- JSON and text response helpers\n",
        "\n",
        "Action Interpreter / Executor\n",
        "- Finance Agent:\n",
        "    * Plans actions like \"fetch_stock\", \"compare_stocks\", \"build_portfolio\"\n",
        "      from natural language using structured JSON output from the LLM.\n",
        "    * Executes actions using Python + yfinance and feeds results back.\n",
        "- File System Agent:\n",
        "    * Summarizes a directory\n",
        "    * Plans file ops (\"mkdir\", \"move\", \"delete_soft\") via LLM\n",
        "    * Validates + safely executes (no path traversal; soft-delete only)\n",
        "\n",
        "User Interface\n",
        "- Streamlit app with multiple tabs:\n",
        "    * Single Stock Explorer\n",
        "    * Finance Agent\n",
        "    * File System Agent\n",
        "    * General AI Chat (with external data)\n",
        "    * Action Logs\n",
        "\n",
        "Error Handling & Safety\n",
        "- Try/catch around API calls\n",
        "- Simple retry/backoff for rate limiting\n",
        "- Path validation for file operations\n",
        "- Dry-run mode + explicit confirmation for destructive operations\n",
        "- Soft delete instead of hard delete\n",
        "- Logs all actions to JSONL and to in-memory session log\n",
        "\n",
        "External Data Sources for Fresh Context\n",
        "---------------------------------------\n",
        "To partially bypass model training cutoffs for *finance-related* questions,\n",
        "this app pulls in **live external data** and passes it into the LLM:\n",
        "\n",
        "1. yfinance\n",
        "   - Recent OHLC data\n",
        "   - Built-in `news` attribute (if available)\n",
        "   - Basic company info, market cap, etc.\n",
        "\n",
        "2. Reddit (no API key required)\n",
        "   - Uses public JSON search: https://www.reddit.com/search.json\n",
        "   - Fetches recent posts for a ticker or keyword (e.g., \"TSLA Q3 earnings\")\n",
        "   - Extracts titles + snippets as \"social sentiment\" context\n",
        "\n",
        "3. Optional: NewsAPI.org (if you configure an API key)\n",
        "   - Set `NEWSAPI_KEY` in your environment\n",
        "   - App will call `https://newsapi.org/v2/everything` for the ticker/keyword\n",
        "   - Extracts fresh article headlines and descriptions\n",
        "\n",
        "All of that context is **injected into the LLM prompt** for:\n",
        "- Single Stock Explorer narrative\n",
        "- Finance Agent tasks\n",
        "- General AI Chat (when asked about earnings/news/etc.)\n",
        "\n",
        "Nothing here is financial advice. This is an educational demo.\n",
        "\"\"\"\n",
        "\n",
        "# ======================================================================================\n",
        "# Imports and Global Configuration\n",
        "# ======================================================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import shutil\n",
        "import textwrap\n",
        "import traceback\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import requests\n",
        "\n",
        "# OpenAI client (support new + old styles)\n",
        "try:\n",
        "    from openai import OpenAI  # type: ignore\n",
        "    _OPENAI_CLIENT_CLASS_AVAILABLE = True\n",
        "except Exception:  # pragma: no cover\n",
        "    _OPENAI_CLIENT_CLASS_AVAILABLE = False\n",
        "    import openai  # type: ignore\n",
        "\n",
        "# ======================================================================================\n",
        "# App Constants\n",
        "# ======================================================================================\n",
        "\n",
        "APP_NAME: str = \"MarketWhisper: AI Financial Storyteller & Agent\"\n",
        "APP_VERSION: str = \"1.2.0\"\n",
        "\n",
        "ROOT_DIR: Path = Path(os.getcwd()).resolve()\n",
        "LOG_DIR: Path = ROOT_DIR / \"agent_logs\"\n",
        "LOG_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "AGENT_LOG_FILE: Path = LOG_DIR / \"agent_actions.jsonl\"\n",
        "FILE_AGENT_TRASH_DIR_NAME: str = \".file_agent_trash\"\n",
        "\n",
        "DEFAULT_FAST_MODEL: str = \"gpt-4o-mini\"\n",
        "DEFAULT_DETAILED_MODEL: str = \"gpt-4o-mini\"\n",
        "\n",
        "MAX_FILE_SUMMARY_ITEMS: int = 250\n",
        "\n",
        "# External news config\n",
        "NEWSAPI_KEY: Optional[str] = os.environ.get(\"NEWSAPI_KEY\")  # optional\n",
        "REDDIT_USER_AGENT: str = \"MarketWhisperBot/1.0 (https://github.com/yourusername/marketwhisper)\"\n",
        "\n",
        "# ======================================================================================\n",
        "# OpenAI Client Setup\n",
        "# ======================================================================================\n",
        "\n",
        "OPENAI_API_KEY: Optional[str] = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    st.error(\"OpenAI API key not found. Please ensure the OPENAI_API_KEY environment variable is set.\")\n",
        "    st.stop()\n",
        "\n",
        "if _OPENAI_CLIENT_CLASS_AVAILABLE:\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "else:  # pragma: no cover\n",
        "    client = openai.OpenAI(api_key=OPENAI_API_KEY)  # type: ignore\n",
        "\n",
        "# ======================================================================================\n",
        "# Utility Functions: Logging, Paths, JSON\n",
        "# ======================================================================================\n",
        "\n",
        "\n",
        "def ensure_dir(path: Union[str, Path]) -> Path:\n",
        "    \"\"\"Ensure that a directory exists, creating it if necessary.\"\"\"\n",
        "    p = Path(path).resolve()\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "    return p\n",
        "\n",
        "\n",
        "def append_jsonl(path: Union[str, Path], record: Dict[str, Any]) -> None:\n",
        "    \"\"\"\n",
        "    Append a JSON record to a `.jsonl` log file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        p = Path(path)\n",
        "        with p.open(\"a\", encoding=\"utf-8\") as f:\n",
        "            json.dump(record, f, ensure_ascii=False)\n",
        "            f.write(\"\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"[append_jsonl] Failed to log record: {e}\", file=sys.stderr)\n",
        "\n",
        "\n",
        "def load_jsonl(path: Union[str, Path], max_lines: int = 5000) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Load up to `max_lines` JSON records from a .jsonl file.\n",
        "    \"\"\"\n",
        "    records: List[Dict[str, Any]] = []\n",
        "    p = Path(path)\n",
        "    if not p.exists():\n",
        "        return records\n",
        "\n",
        "    try:\n",
        "        with p.open(\"r\", encoding=\"utf-8\") as f:\n",
        "            for idx, line in enumerate(f):\n",
        "                if idx >= max_lines:\n",
        "                    break\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                try:\n",
        "                    rec = json.loads(line)\n",
        "                    records.append(rec)\n",
        "                except json.JSONDecodeError:\n",
        "                    # Skip malformed line\n",
        "                    continue\n",
        "    except Exception as e:\n",
        "        print(f\"[load_jsonl] Failed to read log file: {e}\", file=sys.stderr)\n",
        "\n",
        "    return records\n",
        "\n",
        "\n",
        "def safe_join(base: Union[str, Path], *parts: str) -> Path:\n",
        "    \"\"\"\n",
        "    Safely join a base directory with additional path parts, preventing path traversal.\n",
        "    \"\"\"\n",
        "    base_path = Path(base).resolve()\n",
        "    final_path = base_path\n",
        "    for part in parts:\n",
        "        final_path = final_path / part\n",
        "\n",
        "    final_path = final_path.resolve()\n",
        "    try:\n",
        "        final_path.relative_to(base_path)\n",
        "    except ValueError:\n",
        "        raise ValueError(f\"Attempted path traversal outside base directory: {final_path}\")\n",
        "\n",
        "    return final_path\n",
        "\n",
        "\n",
        "def format_exception(e: BaseException) -> str:\n",
        "    \"\"\"Format an exception and traceback as a short string.\"\"\"\n",
        "    return f\"{e.__class__.__name__}: {str(e)}\"\n",
        "\n",
        "\n",
        "def short_uid(prefix: str = \"id\") -> str:\n",
        "    \"\"\"\n",
        "    Small unique-ish ID for logging / action IDs.\n",
        "    \"\"\"\n",
        "    ts = int(time.time())\n",
        "    rand = int((time.time() - ts) * 10000)\n",
        "    return f\"{prefix}-{ts}-{rand}\"\n",
        "\n",
        "\n",
        "# ======================================================================================\n",
        "# LLM Helper Functions (with basic retry / backoff)\n",
        "# ======================================================================================\n",
        "\n",
        "\n",
        "def _openai_chat_completion(\n",
        "    messages: List[Dict[str, str]],\n",
        "    model: str,\n",
        "    max_tokens: int,\n",
        "    temperature: float,\n",
        "    response_format: Optional[Dict[str, Any]] = None,\n",
        "    max_retries: int = 3,\n",
        "    base_backoff: float = 1.0,\n",
        "):\n",
        "    \"\"\"\n",
        "    Low-level wrapper for client.chat.completions.create with simple retry/backoff.\n",
        "\n",
        "    Retries on:\n",
        "    - Probable rate-limit (HTTP 429)\n",
        "    - Probable server errors (HTTP 5xx / \"temporarily unavailable\")\n",
        "\n",
        "    Does NOT silently swallow errors: if it fails after retries,\n",
        "    it re-raises the last exception.\n",
        "    \"\"\"\n",
        "    backoff = base_backoff\n",
        "    last_error: Optional[Exception] = None\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            kwargs: Dict[str, Any] = {\n",
        "                \"model\": model,\n",
        "                \"messages\": messages,\n",
        "                \"max_tokens\": max_tokens,\n",
        "                \"temperature\": temperature,\n",
        "            }\n",
        "            if response_format is not None:\n",
        "                kwargs[\"response_format\"] = response_format\n",
        "\n",
        "            completion = client.chat.completions.create(**kwargs)\n",
        "            return completion\n",
        "\n",
        "        except Exception as e:\n",
        "            last_error = e\n",
        "            msg = str(e).lower()\n",
        "            is_rate_limit = \"rate limit\" in msg or \"429\" in msg\n",
        "            is_server_error = \"500\" in msg or \"503\" in msg or \"temporarily unavailable\" in msg\n",
        "\n",
        "            if attempt < max_retries - 1 and (is_rate_limit or is_server_error):\n",
        "                time.sleep(backoff)\n",
        "                backoff *= 2\n",
        "                continue\n",
        "            break\n",
        "\n",
        "    if last_error:\n",
        "        raise last_error\n",
        "    raise RuntimeError(\"Unknown error calling OpenAI API\")\n",
        "\n",
        "\n",
        "def call_llm_json(\n",
        "    system_prompt: str,\n",
        "    user_prompt: str,\n",
        "    model: str = DEFAULT_FAST_MODEL,\n",
        "    max_tokens: int = 800,\n",
        "    temperature: float = 0.2,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Call the LLM and ask for a JSON object using `response_format={\"type\": \"json_object\"}`.\n",
        "    \"\"\"\n",
        "    completion = _openai_chat_completion(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt},\n",
        "        ],\n",
        "        model=model,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        response_format={\"type\": \"json_object\"},\n",
        "    )\n",
        "    content = completion.choices[0].message.content\n",
        "    try:\n",
        "        data = json.loads(content)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        # Surface the actual content in logs for debugging, but not in UI\n",
        "        print(f\"[call_llm_json] Failed to parse JSON. Raw content:\\n{content}\", file=sys.stderr)\n",
        "        raise RuntimeError(f\"Failed to parse JSON from LLM: {format_exception(e)}\")\n",
        "\n",
        "\n",
        "def call_llm_text(\n",
        "    system_prompt: str,\n",
        "    user_prompt: str,\n",
        "    model: str = DEFAULT_FAST_MODEL,\n",
        "    max_tokens: int = 800,\n",
        "    temperature: float = 0.7,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Call the LLM and get back plain text.\n",
        "    \"\"\"\n",
        "    completion = _openai_chat_completion(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt},\n",
        "        ],\n",
        "        model=model,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        response_format=None,\n",
        "    )\n",
        "    return completion.choices[0].message.content.strip()\n",
        "\n",
        "\n",
        "# ======================================================================================\n",
        "# External Data Fetchers (Reddit + Optional NewsAPI + yfinance news merge)\n",
        "# ======================================================================================\n",
        "\n",
        "def fetch_reddit_posts(\n",
        "    query: str,\n",
        "    limit: int = 10,\n",
        "    sort: str = \"new\",\n",
        "    timeout: float = 6.0,\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Fetch a small set of Reddit posts using the public search JSON endpoint.\n",
        "    This does **not** require an API key, but is rate-limited and best-effort.\n",
        "\n",
        "    Returns a list of dicts with keys:\n",
        "        - \"title\"\n",
        "        - \"subreddit\"\n",
        "        - \"score\"\n",
        "        - \"num_comments\"\n",
        "        - \"url\"\n",
        "        - \"created_utc\"\n",
        "    \"\"\"\n",
        "    results: List[Dict[str, Any]] = []\n",
        "    try:\n",
        "        url = \"https://www.reddit.com/search.json\"\n",
        "        params = {\"q\": query, \"limit\": limit, \"sort\": sort, \"restrict_sr\": False}\n",
        "        headers = {\"User-Agent\": REDDIT_USER_AGENT}\n",
        "        resp = requests.get(url, params=params, headers=headers, timeout=timeout)\n",
        "        if resp.status_code != 200:\n",
        "            return []\n",
        "\n",
        "        data = resp.json()\n",
        "        children = data.get(\"data\", {}).get(\"children\", [])\n",
        "        for child in children:\n",
        "            post = child.get(\"data\", {})\n",
        "            results.append(\n",
        "                {\n",
        "                    \"title\": post.get(\"title\", \"\"),\n",
        "                    \"subreddit\": post.get(\"subreddit\", \"\"),\n",
        "                    \"score\": post.get(\"score\", 0),\n",
        "                    \"num_comments\": post.get(\"num_comments\", 0),\n",
        "                    \"url\": \"https://www.reddit.com\" + post.get(\"permalink\", \"\"),\n",
        "                    \"created_utc\": post.get(\"created_utc\"),\n",
        "                }\n",
        "            )\n",
        "    except Exception as e:\n",
        "        print(f\"[fetch_reddit_posts] Error: {format_exception(e)}\", file=sys.stderr)\n",
        "        return []\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def fetch_newsapi_articles(\n",
        "    query: str,\n",
        "    language: str = \"en\",\n",
        "    page_size: int = 10,\n",
        "    timeout: float = 6.0,\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Fetch recent news articles using NewsAPI, **if** NEWSAPI_KEY is set.\n",
        "\n",
        "    Returns a list of dicts:\n",
        "        - \"title\"\n",
        "        - \"description\"\n",
        "        - \"url\"\n",
        "        - \"published_at\"\n",
        "        - \"source\"\n",
        "    \"\"\"\n",
        "    if not NEWSAPI_KEY:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        url = \"https://newsapi.org/v2/everything\"\n",
        "        params = {\n",
        "            \"q\": query,\n",
        "            \"language\": language,\n",
        "            \"pageSize\": page_size,\n",
        "            \"sortBy\": \"publishedAt\",\n",
        "            \"apiKey\": NEWSAPI_KEY,\n",
        "        }\n",
        "        resp = requests.get(url, params=params, timeout=timeout)\n",
        "        if resp.status_code != 200:\n",
        "            print(\n",
        "                f\"[fetch_newsapi_articles] Non-200 status {resp.status_code}: {resp.text[:200]}\",\n",
        "                file=sys.stderr,\n",
        "            )\n",
        "            return []\n",
        "\n",
        "        data = resp.json()\n",
        "        articles_raw = data.get(\"articles\", [])\n",
        "        articles: List[Dict[str, Any]] = []\n",
        "        for a in articles_raw:\n",
        "            articles.append(\n",
        "                {\n",
        "                    \"title\": a.get(\"title\") or \"\",\n",
        "                    \"description\": a.get(\"description\") or \"\",\n",
        "                    \"url\": a.get(\"url\") or \"\",\n",
        "                    \"published_at\": a.get(\"publishedAt\") or \"\",\n",
        "                    \"source\": (a.get(\"source\") or {}).get(\"name\") or \"\",\n",
        "                }\n",
        "            )\n",
        "        return articles\n",
        "    except Exception as e:\n",
        "        print(f\"[fetch_newsapi_articles] Error: {format_exception(e)}\", file=sys.stderr)\n",
        "        return []\n",
        "\n",
        "\n",
        "def merge_news_sources(\n",
        "    ticker: str,\n",
        "    yf_news: List[Dict[str, Any]],\n",
        "    newsapi_articles: List[Dict[str, Any]],\n",
        "    reddit_posts: List[Dict[str, Any]],\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Combine news from yfinance, NewsAPI, and Reddit into a single structure.\n",
        "\n",
        "    Returns:\n",
        "        {\n",
        "            \"headlines\": [ ... ],\n",
        "            \"reddit_summaries\": [ ... ],\n",
        "            \"newsapi_summaries\": [ ... ]\n",
        "        }\n",
        "    \"\"\"\n",
        "    headlines: List[str] = []\n",
        "    for item in (yf_news or [])[:10]:\n",
        "        title = item.get(\"title\")\n",
        "        if title:\n",
        "            headlines.append(title)\n",
        "\n",
        "    newsapi_summaries: List[str] = []\n",
        "    for a in newsapi_articles[:10]:\n",
        "        title = a.get(\"title\", \"\")\n",
        "        desc = a.get(\"description\", \"\")\n",
        "        source = a.get(\"source\", \"\")\n",
        "        combined = f\"{title} — {desc}\".strip(\" —\")\n",
        "        if source:\n",
        "            combined += f\" (Source: {source})\"\n",
        "        if combined:\n",
        "            newsapi_summaries.append(combined)\n",
        "\n",
        "    reddit_summaries: List[str] = []\n",
        "    for p in reddit_posts[:10]:\n",
        "        title = p.get(\"title\", \"\")\n",
        "        sub = p.get(\"subreddit\", \"\")\n",
        "        score = p.get(\"score\", 0)\n",
        "        comments = p.get(\"num_comments\", 0)\n",
        "        if title:\n",
        "            reddit_summaries.append(\n",
        "                f\"[r/{sub}] {title} (score: {score}, comments: {comments})\"\n",
        "            )\n",
        "\n",
        "    # Deduplicate headlines-ish\n",
        "    def dedupe(seq: List[str]) -> List[str]:\n",
        "        seen = set()\n",
        "        out = []\n",
        "        for s in seq:\n",
        "            key = s.strip().lower()\n",
        "            if not key or key in seen:\n",
        "                continue\n",
        "            seen.add(key)\n",
        "            out.append(s)\n",
        "        return out\n",
        "\n",
        "    return {\n",
        "        \"headlines\": dedupe(headlines),\n",
        "        \"reddit_summaries\": dedupe(reddit_summaries),\n",
        "        \"newsapi_summaries\": dedupe(newsapi_summaries),\n",
        "    }\n",
        "\n",
        "\n",
        "def gather_external_market_context(\n",
        "    ticker: str,\n",
        "    extra_query: Optional[str] = None,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    High-level helper to gather external market context for a ticker.\n",
        "\n",
        "    - Uses yfinance's `.news` as base\n",
        "    - Augments with:\n",
        "        * Reddit search\n",
        "        * Optional NewsAPI search if available\n",
        "\n",
        "    Returns a dict:\n",
        "        {\n",
        "            \"combined_text\": \"...\",\n",
        "            \"sources\": {\n",
        "                \"yf_news\": [...],\n",
        "                \"reddit_posts\": [...],\n",
        "                \"newsapi_articles\": [...]\n",
        "            }\n",
        "        }\n",
        "    \"\"\"\n",
        "    ticker_str = ticker.upper().strip()\n",
        "\n",
        "    # yfinance news\n",
        "    stock = yf.Ticker(ticker_str)\n",
        "    yf_news = getattr(stock, \"news\", []) or []\n",
        "\n",
        "    # Query string (can incorporate an extra phrase like \"Q3 earnings\")\n",
        "    if extra_query:\n",
        "        query = f\"{ticker_str} {extra_query}\"\n",
        "    else:\n",
        "        query = ticker_str\n",
        "\n",
        "    reddit_posts = fetch_reddit_posts(query=query, limit=10)\n",
        "    newsapi_articles = fetch_newsapi_articles(query=query, page_size=10)\n",
        "\n",
        "    merged = merge_news_sources(\n",
        "        ticker=ticker_str,\n",
        "        yf_news=yf_news,\n",
        "        newsapi_articles=newsapi_articles,\n",
        "        reddit_posts=reddit_posts,\n",
        "    )\n",
        "\n",
        "    # Build a text blob to feed into the LLM\n",
        "    parts: List[str] = []\n",
        "\n",
        "    if merged[\"headlines\"]:\n",
        "        parts.append(\"Market/financial headlines:\")\n",
        "        for h in merged[\"headlines\"]:\n",
        "            parts.append(f\"- {h}\")\n",
        "\n",
        "    if merged[\"newsapi_summaries\"]:\n",
        "        parts.append(\"\")\n",
        "        parts.append(\"News articles (NewsAPI):\")\n",
        "        for s in merged[\"newsapi_summaries\"]:\n",
        "            parts.append(f\"- {s}\")\n",
        "\n",
        "    if merged[\"reddit_summaries\"]:\n",
        "        parts.append(\"\")\n",
        "        parts.append(\"Reddit social sentiment / posts:\")\n",
        "        for s in merged[\"reddit_summaries\"]:\n",
        "            parts.append(f\"- {s}\")\n",
        "\n",
        "    combined_text = \"\\n\".join(parts).strip()\n",
        "\n",
        "    return {\n",
        "        \"combined_text\": combined_text,\n",
        "        \"sources\": {\n",
        "            \"yf_news\": yf_news,\n",
        "            \"reddit_posts\": reddit_posts,\n",
        "            \"newsapi_articles\": newsapi_articles,\n",
        "        },\n",
        "    }\n",
        "\n",
        "\n",
        "# ======================================================================================\n",
        "# Finance Domain Functions (yfinance + external context)\n",
        "# ======================================================================================\n",
        "\n",
        "\n",
        "def fetch_stock_data(ticker: str, period: str) -> Tuple[Optional[float], Any, Any, str, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Fetch stock history, recommendations, news, and basic info using yfinance.\n",
        "\n",
        "    NOTE (chart correctness):\n",
        "    - We explicitly sort the history index by time.\n",
        "    - We ensure it's a simple, single-level DateTimeIndex.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        stock = yf.Ticker(ticker)\n",
        "        hist = stock.history(period=period)\n",
        "\n",
        "        if hist is None or hist.empty:\n",
        "            return None, None, None, \"\", {}\n",
        "\n",
        "        # Ensure history is sorted and cleaned\n",
        "        hist = hist.copy()\n",
        "        hist.sort_index(inplace=True)\n",
        "\n",
        "        # Just to be safe: drop any duplicated indices\n",
        "        hist = hist[~hist.index.duplicated(keep=\"last\")]\n",
        "\n",
        "        recommendations = getattr(stock, \"recommendations\", None)\n",
        "        news = getattr(stock, \"news\", []) or []\n",
        "        info = getattr(stock, \"info\", {}) or {}\n",
        "\n",
        "        price_change: Optional[float] = None\n",
        "        if len(hist) > 1:\n",
        "            last_close = hist[\"Close\"].iloc[-1]\n",
        "            prev_close = hist[\"Close\"].iloc[-2]\n",
        "            if prev_close != 0:\n",
        "                price_change = ((last_close - prev_close) / prev_close) * 100.0\n",
        "                price_change = round(price_change, 2)\n",
        "\n",
        "        news_headlines: List[str] = [\n",
        "            item.get(\"title\", \"No Title Available\") for item in news[:5] if item.get(\"title\")\n",
        "        ]\n",
        "        news_text = \". \".join(news_headlines)\n",
        "\n",
        "        return price_change, hist, recommendations, news_text, info\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error fetching data for {ticker}: {e}\")\n",
        "        return None, None, None, \"\", {}\n",
        "\n",
        "\n",
        "def get_current_price(ticker: str) -> Optional[float]:\n",
        "    \"\"\"Get the latest close price for a ticker.\"\"\"\n",
        "    try:\n",
        "        stock = yf.Ticker(ticker)\n",
        "        hist = stock.history(period=\"1d\")\n",
        "        if hist is None or hist.empty:\n",
        "            return None\n",
        "        hist = hist.copy()\n",
        "        hist.sort_index(inplace=True)\n",
        "        return float(hist[\"Close\"].iloc[-1])\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def mock_sentiment_score(ticker: str) -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Deterministic mock sentiment score used as fallback.\n",
        "\n",
        "    This is used when:\n",
        "    - No usable external context is available, or\n",
        "    - LLM sentiment analysis fails.\n",
        "    \"\"\"\n",
        "    np.random.seed(hash(ticker) % (2**32))\n",
        "    bullish = np.random.uniform(40, 80)\n",
        "    bearish = 100 - bullish\n",
        "    return round(bullish, 1), round(bearish, 1)\n",
        "\n",
        "\n",
        "def analyze_sentiment_with_llm(\n",
        "    ticker: str,\n",
        "    base_news_text: str,\n",
        "    external_context: Optional[str] = None,\n",
        ") -> Tuple[float, float, str]:\n",
        "    \"\"\"\n",
        "    Use the LLM to turn recent news + external context into a bullish/bearish score.\n",
        "\n",
        "    - `base_news_text`: the yfinance headlines string\n",
        "    - `external_context`: combined text from gather_external_market_context\n",
        "    \"\"\"\n",
        "    combined_text = \"\"\n",
        "\n",
        "    if base_news_text.strip():\n",
        "        combined_text += \"YFINANCE HEADLINES:\\n\" + base_news_text.strip() + \"\\n\\n\"\n",
        "\n",
        "    if external_context and external_context.strip():\n",
        "        combined_text += \"EXTERNAL CONTEXT (NewsAPI/Reddit/etc.):\\n\" + external_context.strip()\n",
        "\n",
        "    if not combined_text.strip():\n",
        "        b, br = mock_sentiment_score(ticker)\n",
        "        return b, br, (\n",
        "            \"Not enough recent news or external context to compute sentiment. \"\n",
        "            \"Using a deterministic demo score instead.\"\n",
        "        )\n",
        "\n",
        "    system_prompt = \"\"\"\n",
        "You are a financial sentiment analyst.\n",
        "\n",
        "You receive a bundle of recent market news and social media snippets\n",
        "for a single stock. You must:\n",
        "- Estimate bullish and bearish sentiment (0-100 each).\n",
        "- Provide a short natural-language explanation.\n",
        "\n",
        "Rules:\n",
        "- Output JSON ONLY with keys: bullish, bearish, summary.\n",
        "- bullish + bearish should be about 100 (does not have to be exact).\n",
        "- Do not be overconfident; avoid 0 or 100.\n",
        "- Focus on *short-term* sentiment (1–4 weeks).\n",
        "\"\"\"\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "Ticker: {ticker}\n",
        "\n",
        "Combined news + social context:\n",
        "{combined_text}\n",
        "\n",
        "Return JSON only.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        data = call_llm_json(\n",
        "            system_prompt=system_prompt,\n",
        "            user_prompt=user_prompt,\n",
        "            model=DEFAULT_FAST_MODEL,\n",
        "            max_tokens=400,\n",
        "            temperature=0.2,\n",
        "        )\n",
        "        bullish = float(data.get(\"bullish\", 50.0))\n",
        "        bearish = float(data.get(\"bearish\", 50.0))\n",
        "        summary = str(data.get(\"summary\", \"No summary provided.\")).strip()\n",
        "        bullish = max(0.0, min(100.0, bullish))\n",
        "        bearish = max(0.0, min(100.0, bearish))\n",
        "        return round(bullish, 1), round(bearish, 1), summary\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Sentiment analyzer fell back to deterministic mode: {format_exception(e)}\")\n",
        "        b, br = mock_sentiment_score(ticker)\n",
        "        return b, br, \"LLM sentiment failed; using a deterministic demo score instead.\"\n",
        "\n",
        "\n",
        "def generate_narrative(\n",
        "    ticker: str,\n",
        "    price_change: Optional[float],\n",
        "    bullish: float,\n",
        "    bearish: float,\n",
        "    base_news_text: str,\n",
        "    recommendations_data: Any,\n",
        "    external_context_text: Optional[str] = None,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Generate a market narrative using the LLM, enriched with external context.\n",
        "\n",
        "    - `base_news_text`: from yfinance headlines\n",
        "    - `external_context_text`: from gather_external_market_context (News + Reddit)\n",
        "    \"\"\"\n",
        "    persona_prompt = \"\"\"\n",
        "You are a senior financial market analyst and storyteller.\n",
        "\n",
        "You explain stock price movements, fundamental factors, analyst views,\n",
        "and social sentiment in a clear, concise, factual manner.\n",
        "\n",
        "Constraints:\n",
        "- Avoid heavy jargon.\n",
        "- Be unbiased and balanced.\n",
        "- Highlight potential bubble risks AND sustained trend drivers.\n",
        "- Never give direct investment advice. You may describe risks, catalysts,\n",
        "  and scenarios instead.\n",
        "\"\"\"\n",
        "\n",
        "    few_shot_examples = \"\"\"\n",
        "Example 1:\n",
        "Stock: AAPL\n",
        "Price Change: +3.5%\n",
        "Sentiment: 75% bullish\n",
        "Recent News (sample): 'Apple announces new chip with improved battery life'\n",
        "Analyst Recommendations (sample): Strong Buy: 5, Buy: 24, Hold: 14, Sell: 2, Strong Sell: 3\n",
        "External Context (sample): Reddit chatter generally positive about performance and ecosystem lock-in.\n",
        "Narrative: Apple’s stock increased by 3.5% following the announcement of its new chip promising longer battery life. Market sentiment is strongly bullish, reflecting optimism around new product demand and ecosystem stickiness. Analyst recommendations are predominantly positive (29 'Strong Buy' or 'Buy' vs. 5 'Sell' or 'Strong Sell'), reinforcing the optimistic medium-term outlook. However, the strong run-up may price in a lot of good news already, leaving the stock vulnerable to short-term pullbacks if execution or guidance disappoint.\n",
        "\n",
        "Example 2:\n",
        "Stock: TSLA\n",
        "Price Change: -4.2%\n",
        "Sentiment: 60% bearish\n",
        "Recent News (sample): 'Tesla faces regulatory scrutiny in Europe'\n",
        "Analyst Recommendations (sample): Strong Buy: 1, Buy: 5, Hold: 10, Sell: 8, Strong Sell: 4\n",
        "External Context (sample): Reddit and Twitter show mixed reactions, with some long-term bulls but concerns about valuation and regulatory risk.\n",
        "Narrative: Tesla's 4.2% decline reflects increased concern over regulatory challenges in Europe and uncertainty around demand in key markets. Sentiment tilts slightly bearish, as more analysts recommend 'Hold' or 'Sell' compared with outright 'Buy' ratings. Online discussion remains polarized: long-term supporters emphasize the company’s technology and brand strength, while skeptics focus on valuation and execution risks. Together, this suggests a more cautious short-term stance while the market waits for clearer signals on regulation and growth.\n",
        "\"\"\"\n",
        "\n",
        "    recommendation_summary = \"Analyst Recommendations: \"\n",
        "    if recommendations_data is not None and hasattr(recommendations_data, \"empty\") and not recommendations_data.empty:\n",
        "        latest_rec = recommendations_data.iloc[0]\n",
        "        recommendation_summary += (\n",
        "            f\"Strong Buy: {latest_rec.get('strongBuy', 'N/A')}, \"\n",
        "            f\"Buy: {latest_rec.get('buy', 'N/A')}, \"\n",
        "            f\"Hold: {latest_rec.get('hold', 'N/A')}, \"\n",
        "            f\"Sell: {latest_rec.get('sell', 'N/A')}, \"\n",
        "            f\"Strong Sell: {latest_rec.get('strongSell', 'N/A')}\"\n",
        "        )\n",
        "    else:\n",
        "        recommendation_summary += \"No recent analyst recommendations available.\"\n",
        "\n",
        "    pc_str = \"N/A\"\n",
        "    if price_change is not None:\n",
        "        pc_str = f\"{price_change:+.2f}%\"\n",
        "\n",
        "    extended_news = base_news_text or \"(no yfinance headlines)\"\n",
        "    if external_context_text:\n",
        "        extended_news += \"\\n\\nExternal context (NewsAPI/Reddit/etc.):\\n\" + external_context_text\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "{persona_prompt}\n",
        "\n",
        "{few_shot_examples}\n",
        "\n",
        "Now analyze this stock using the same tone, level of detail, and structure.\n",
        "\n",
        "Stock: {ticker.upper()}\n",
        "Price Change: {pc_str}\n",
        "Sentiment: {bullish}% bullish, {bearish}% bearish\n",
        "Recent News + Context:\n",
        "{extended_news}\n",
        "{recommendation_summary}\n",
        "\n",
        "Write a concise narrative (6–10 sentences) that:\n",
        "- explains recent price behavior in plain language,\n",
        "- describes how sentiment and news might be connected,\n",
        "- highlights 1–2 key risks and 1–2 potential catalysts,\n",
        "- clearly avoids direct \"buy/sell\" recommendations.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        narrative = call_llm_text(\n",
        "            system_prompt=persona_prompt,\n",
        "            user_prompt=user_prompt,\n",
        "            model=DEFAULT_DETAILED_MODEL,\n",
        "            max_tokens=650,\n",
        "            temperature=0.65,\n",
        "        )\n",
        "        return narrative.strip()\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error generating narrative: {format_exception(e)}\")\n",
        "        return \"Could not generate narrative due to an LLM error.\"\n",
        "\n",
        "\n",
        "def compare_stocks(\n",
        "    tickers: List[str],\n",
        "    period: str = \"6mo\",\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Fetch and compare multiple tickers over a given period.\n",
        "\n",
        "    - Returns normalized price series (starting at 100)\n",
        "    - Computes simple returns\n",
        "    - Generates a short narrative using the LLM\n",
        "    \"\"\"\n",
        "    results: Dict[str, pd.Series] = {}\n",
        "    returns: Dict[str, float] = {}\n",
        "\n",
        "    for t in tickers:\n",
        "        price_change, hist, _, _, _ = fetch_stock_data(t, period)\n",
        "        if hist is None or hist.empty:\n",
        "            continue\n",
        "        close = hist[\"Close\"].copy()\n",
        "        close = close.sort_index()\n",
        "        normalized = close / close.iloc[0] * 100.0\n",
        "        results[t] = normalized\n",
        "        if price_change is not None:\n",
        "            returns[t] = price_change\n",
        "\n",
        "    if not results:\n",
        "        return {\n",
        "            \"tickers\": tickers,\n",
        "            \"period\": period,\n",
        "            \"returns\": {},\n",
        "            \"normalized_prices\": pd.DataFrame(),\n",
        "            \"analysis\": \"Could not load any of the requested tickers.\",\n",
        "        }\n",
        "\n",
        "    df_norm = pd.DataFrame(results)\n",
        "\n",
        "    summary_text = \" | \".join([f\"{t}: {r:+.2f}%\" for t, r in returns.items()])\n",
        "    prompt = f\"\"\"\n",
        "You are a portfolio analyst.\n",
        "\n",
        "Here are approximate recent returns over the period '{period}':\n",
        "{summary_text}\n",
        "\n",
        "Explain, in a short paragraph, how these stocks performed relative to each other\n",
        "and what a casual investor might notice. Avoid giving direct investment advice.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        analysis = call_llm_text(\n",
        "            system_prompt=\"You explain relative stock performance in a neutral, educational way.\",\n",
        "            user_prompt=prompt,\n",
        "            model=DEFAULT_FAST_MODEL,\n",
        "            max_tokens=400,\n",
        "            temperature=0.6,\n",
        "        )\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Could not generate comparison narrative: {format_exception(e)}\")\n",
        "        analysis = \"Comparison narrative unavailable due to an LLM error.\"\n",
        "\n",
        "    return {\n",
        "        \"tickers\": tickers,\n",
        "        \"period\": period,\n",
        "        \"returns\": returns,\n",
        "        \"normalized_prices\": df_norm,\n",
        "        \"analysis\": analysis,\n",
        "    }\n",
        "\n",
        "\n",
        "def build_portfolio_allocation(\n",
        "    tickers: List[str],\n",
        "    capital: float,\n",
        "    risk_level: str = \"balanced\",\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Build a very simple equal-weight model portfolio across the given tickers.\n",
        "\n",
        "    This is intentionally not \"smart\" – it is an educational example.\n",
        "    \"\"\"\n",
        "    prices: Dict[str, float] = {}\n",
        "    for t in tickers:\n",
        "        price = get_current_price(t)\n",
        "        if price is not None and price > 0:\n",
        "            prices[t] = price\n",
        "\n",
        "    if not prices:\n",
        "        return {\n",
        "            \"capital\": capital,\n",
        "            \"risk_level\": risk_level,\n",
        "            \"allocations\": [],\n",
        "            \"cash_left\": capital,\n",
        "            \"explanation\": \"Could not fetch prices for any ticker.\",\n",
        "        }\n",
        "\n",
        "    n = len(prices)\n",
        "    equal_weight = 1.0 / n\n",
        "    dollars_per_ticker = capital * equal_weight\n",
        "\n",
        "    allocations: List[Dict[str, Any]] = []\n",
        "    total_invested = 0.0\n",
        "\n",
        "    for t, price in prices.items():\n",
        "        shares = int(dollars_per_ticker // price)\n",
        "        invested = shares * price\n",
        "        total_invested += invested\n",
        "        weight_pct = (invested / capital * 100.0) if capital > 0 else 0.0\n",
        "        allocations.append(\n",
        "            {\n",
        "                \"ticker\": t,\n",
        "                \"price\": round(price, 2),\n",
        "                \"shares\": int(shares),\n",
        "                \"invested\": round(invested, 2),\n",
        "                \"weight_pct\": round(weight_pct, 2),\n",
        "            }\n",
        "        )\n",
        "\n",
        "    cash_left = round(capital - total_invested, 2)\n",
        "\n",
        "    description = \"\\n\".join(\n",
        "        [f\"{a['ticker']}: {a['shares']} shares (~${a['invested']})\" for a in allocations]\n",
        "    )\n",
        "    prompt = f\"\"\"\n",
        "You are a portfolio explainer bot.\n",
        "\n",
        "The user has a {risk_level} risk profile and {capital:.2f} USD of capital.\n",
        "We built an equal-weight demo portfolio with these positions:\n",
        "{description}\n",
        "Uninvested cash: {cash_left:.2f} USD.\n",
        "\n",
        "Explain in 4–6 sentences what this simple allocation is doing,\n",
        "what kind of risk profile it roughly corresponds to, and 1–2 things\n",
        "the user should pay attention to (without giving direct financial advice).\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        explanation = call_llm_text(\n",
        "            system_prompt=\"You explain portfolios in friendly, non-advisory language.\",\n",
        "            user_prompt=prompt,\n",
        "            model=DEFAULT_FAST_MODEL,\n",
        "            max_tokens=350,\n",
        "            temperature=0.7,\n",
        "        )\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Could not generate portfolio explanation: {format_exception(e)}\")\n",
        "        explanation = (\n",
        "            \"This is a simple equal-weight portfolio across the selected tickers. \"\n",
        "            \"It is for demonstration only and not financial advice.\"\n",
        "        )\n",
        "\n",
        "    return {\n",
        "        \"capital\": capital,\n",
        "        \"risk_level\": risk_level,\n",
        "        \"allocations\": allocations,\n",
        "        \"cash_left\": cash_left,\n",
        "        \"explanation\": explanation,\n",
        "    }\n",
        "\n",
        "\n",
        "# ======================================================================================\n",
        "# Finance Agent Planner & Executor\n",
        "# ======================================================================================\n",
        "\n",
        "def plan_finance_agent(user_goal: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Turn a natural-language goal into a JSON action plan for the finance domain.\n",
        "\n",
        "    Available action types:\n",
        "\n",
        "        1. \"fetch_stock\"\n",
        "           params: {\"ticker\": \"AAPL\", \"period\": \"6mo\"}\n",
        "\n",
        "        2. \"compare_stocks\"\n",
        "           params: {\"tickers\": [\"AAPL\", \"MSFT\"], \"period\": \"1y\"}\n",
        "\n",
        "        3. \"build_portfolio\"\n",
        "           params: {\"tickers\": [\"AAPL\", \"MSFT\"], \"capital\": 10000, \"risk_level\": \"balanced\"}\n",
        "\n",
        "        4. \"external_news_only\"\n",
        "           params: {\"ticker\": \"NVDA\", \"query\": \"Q3 earnings\"}  # gather context only\n",
        "\n",
        "    The planner is intentionally flexible: if the user mixes \"analyze NVDA Q3 earnings\"\n",
        "    and \"compare it with AMD\", the agent can choose multiple actions.\n",
        "\n",
        "    It returns ONLY JSON:\n",
        "        {\n",
        "          \"plan\": \"short description\",\n",
        "          \"actions\": [\n",
        "             {\"id\": \"step1\", \"type\": \"...\", \"params\": {...}},\n",
        "             ...\n",
        "          ]\n",
        "        }\n",
        "    \"\"\"\n",
        "    system_prompt = \"\"\"\n",
        "You are a planning agent for a stock-market assistant.\n",
        "\n",
        "Your job:\n",
        "- Read the user's goal.\n",
        "- Decide what *structured* actions to run.\n",
        "- Return a JSON plan with a small list of actions.\n",
        "\n",
        "Available action types:\n",
        "\n",
        "1. \"fetch_stock\"\n",
        "   params: {\"ticker\": \"AAPL\", \"period\": \"6mo\"}  # period optional\n",
        "   Use when the user wants an in-depth look at 1 stock.\n",
        "\n",
        "2. \"compare_stocks\"\n",
        "   params: {\"tickers\": [\"AAPL\", \"MSFT\"], \"period\": \"1y\"}  # period optional\n",
        "   Use when the user explicitly asks to compare multiple stocks.\n",
        "\n",
        "3. \"build_portfolio\"\n",
        "   params: {\"tickers\": [\"AAPL\", \"MSFT\"], \"capital\": 10000, \"risk_level\": \"conservative\"|\"balanced\"|\"aggressive\"}\n",
        "   Use when the user mentions an amount of money to allocate across multiple tickers.\n",
        "\n",
        "4. \"external_news_only\"\n",
        "   params: {\"ticker\": \"NVDA\", \"query\": \"Q3 earnings\"}  # query optional\n",
        "   Use when the user mostly wants a narrative about *very recent news / earnings*,\n",
        "   and not so much charts or portfolio math.\n",
        "\n",
        "Return ONLY valid JSON with this structure:\n",
        "{\n",
        "  \"plan\": \"short natural language description of what you will do\",\n",
        "  \"actions\": [\n",
        "     {\"id\": \"step1\", \"type\": \"...\", \"params\": {...}},\n",
        "     ...\n",
        "  ]\n",
        "}\n",
        "\n",
        "If the request is clearly unrelated to finance/markets, return:\n",
        "{\"plan\": \"no_actions_needed\", \"actions\": []}\n",
        "\"\"\"\n",
        "\n",
        "    user_prompt = f\"User goal: {user_goal}\"\n",
        "\n",
        "    plan = call_llm_json(\n",
        "        system_prompt=system_prompt,\n",
        "        user_prompt=user_prompt,\n",
        "        model=DEFAULT_FAST_MODEL,\n",
        "        max_tokens=700,\n",
        "        temperature=0.25,\n",
        "    )\n",
        "    return plan\n",
        "\n",
        "\n",
        "def execute_finance_agent_actions(\n",
        "    plan_json: Dict[str, Any],\n",
        "    use_llm_sentiment: bool = True,\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Execute the finance actions produced by `plan_finance_agent`.\n",
        "    \"\"\"\n",
        "    results: List[Dict[str, Any]] = []\n",
        "    actions = plan_json.get(\"actions\", []) if isinstance(plan_json, dict) else []\n",
        "\n",
        "    if not isinstance(actions, list):\n",
        "        actions = []\n",
        "\n",
        "    for action in actions:\n",
        "        atype = action.get(\"type\")\n",
        "        params = action.get(\"params\", {}) or {}\n",
        "\n",
        "        if atype == \"fetch_stock\":\n",
        "            ticker = params.get(\"ticker\")\n",
        "            period = params.get(\"period\", \"6mo\")\n",
        "            if not ticker:\n",
        "                results.append({\"type\": \"error\", \"error\": \"fetch_stock action missing 'ticker'.\"})\n",
        "                continue\n",
        "\n",
        "            price_change, hist, recs, news_text, info = fetch_stock_data(ticker, period)\n",
        "            if hist is None or hist.empty:\n",
        "                results.append({\"type\": \"error\", \"error\": f\"Could not load data for {ticker}.\"})\n",
        "                continue\n",
        "\n",
        "            external_ctx_obj = gather_external_market_context(ticker)\n",
        "            external_ctx_text = external_ctx_obj.get(\"combined_text\", \"\")\n",
        "\n",
        "            if use_llm_sentiment:\n",
        "                bullish, bearish, sentiment_summary = analyze_sentiment_with_llm(\n",
        "                    ticker,\n",
        "                    base_news_text=news_text or \"\",\n",
        "                    external_context=external_ctx_text,\n",
        "                )\n",
        "            else:\n",
        "                bullish, bearish = mock_sentiment_score(ticker)\n",
        "                sentiment_summary = (\n",
        "                    \"Deterministic demo sentiment score (LLM sentiment disabled).\"\n",
        "                )\n",
        "\n",
        "            narrative = generate_narrative(\n",
        "                ticker=ticker,\n",
        "                price_change=price_change,\n",
        "                bullish=bullish,\n",
        "                bearish=bearish,\n",
        "                base_news_text=news_text,\n",
        "                recommendations_data=recs,\n",
        "                external_context_text=external_ctx_text,\n",
        "            )\n",
        "\n",
        "            results.append(\n",
        "                {\n",
        "                    \"type\": \"fetch_stock\",\n",
        "                    \"ticker\": ticker,\n",
        "                    \"period\": period,\n",
        "                    \"price_change\": price_change,\n",
        "                    \"hist\": hist,\n",
        "                    \"recommendations\": recs,\n",
        "                    \"news_text\": news_text,\n",
        "                    \"info\": info,\n",
        "                    \"bullish\": bullish,\n",
        "                    \"bearish\": bearish,\n",
        "                    \"sentiment_summary\": sentiment_summary,\n",
        "                    \"external_context\": external_ctx_text,\n",
        "                    \"narrative\": narrative,\n",
        "                }\n",
        "            )\n",
        "\n",
        "        elif atype == \"compare_stocks\":\n",
        "            tickers = params.get(\"tickers\", [])\n",
        "            period = params.get(\"period\", \"6mo\")\n",
        "            if not tickers or len(tickers) < 2:\n",
        "                results.append({\"type\": \"error\", \"error\": \"compare_stocks needs at least 2 tickers.\"})\n",
        "                continue\n",
        "            comp = compare_stocks(tickers, period)\n",
        "            comp[\"type\"] = \"compare_stocks\"\n",
        "            results.append(comp)\n",
        "\n",
        "        elif atype == \"build_portfolio\":\n",
        "            tickers = params.get(\"tickers\", [])\n",
        "            try:\n",
        "                capital = float(params.get(\"capital\", 0))\n",
        "            except Exception:\n",
        "                capital = 0.0\n",
        "            risk_level = params.get(\"risk_level\", \"balanced\")\n",
        "            if not tickers or capital <= 0:\n",
        "                results.append(\n",
        "                    {\n",
        "                        \"type\": \"error\",\n",
        "                        \"error\": \"build_portfolio needs 'tickers' and a positive 'capital' amount.\",\n",
        "                    }\n",
        "                )\n",
        "                continue\n",
        "            portfolio = build_portfolio_allocation(tickers, capital, risk_level)\n",
        "            portfolio[\"type\"] = \"build_portfolio\"\n",
        "            results.append(portfolio)\n",
        "\n",
        "        elif atype == \"external_news_only\":\n",
        "            ticker = params.get(\"ticker\")\n",
        "            query = params.get(\"query\") or \"recent news\"\n",
        "            if not ticker:\n",
        "                results.append({\"type\": \"error\", \"error\": \"external_news_only requires 'ticker'.\"})\n",
        "                continue\n",
        "\n",
        "            # We still fetch some basic price info, but the focus is narrative.\n",
        "            price_change, hist, recs, news_text, info = fetch_stock_data(ticker, \"1mo\")\n",
        "\n",
        "            external_ctx_obj = gather_external_market_context(ticker, extra_query=query)\n",
        "            external_ctx_text = external_ctx_obj.get(\"combined_text\", \"\")\n",
        "\n",
        "            if use_llm_sentiment:\n",
        "                bullish, bearish, sentiment_summary = analyze_sentiment_with_llm(\n",
        "                    ticker,\n",
        "                    base_news_text=news_text or \"\",\n",
        "                    external_context=external_ctx_text,\n",
        "                )\n",
        "            else:\n",
        "                bullish, bearish = mock_sentiment_score(ticker)\n",
        "                sentiment_summary = \"Deterministic demo sentiment score (LLM sentiment disabled).\"\n",
        "\n",
        "            narrative = generate_narrative(\n",
        "                ticker=ticker,\n",
        "                price_change=price_change,\n",
        "                bullish=bullish,\n",
        "                bearish=bearish,\n",
        "                base_news_text=news_text,\n",
        "                recommendations_data=recs,\n",
        "                external_context_text=external_ctx_text,\n",
        "            )\n",
        "\n",
        "            results.append(\n",
        "                {\n",
        "                    \"type\": \"external_news_only\",\n",
        "                    \"ticker\": ticker,\n",
        "                    \"query\": query,\n",
        "                    \"external_context\": external_ctx_text,\n",
        "                    \"price_change\": price_change,\n",
        "                    \"bullish\": bullish,\n",
        "                    \"bearish\": bearish,\n",
        "                    \"sentiment_summary\": sentiment_summary,\n",
        "                    \"narrative\": narrative,\n",
        "                }\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            results.append(\n",
        "                {\n",
        "                    \"type\": \"error\",\n",
        "                    \"error\": f\"Unknown action type: {atype}\",\n",
        "                    \"raw_action\": action,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# ======================================================================================\n",
        "# File System Agent: Summarization, Planning, Validation, Execution\n",
        "# ======================================================================================\n",
        "\n",
        "def summarize_directory(\n",
        "    base_dir: Union[str, Path],\n",
        "    max_items: int = MAX_FILE_SUMMARY_ITEMS,\n",
        "    max_depth: int = 2,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Summarize the contents of a directory for the file agent.\n",
        "    \"\"\"\n",
        "    base = Path(base_dir).resolve()\n",
        "    if not base.exists() or not base.is_dir():\n",
        "        raise ValueError(f\"Base directory does not exist or is not a directory: {base}\")\n",
        "\n",
        "    items: List[Dict[str, Any]] = []\n",
        "    truncated = False\n",
        "\n",
        "    for root, dirs, files in os.walk(base):\n",
        "        current = Path(root)\n",
        "        try:\n",
        "            rel = current.relative_to(base)\n",
        "            depth = len(rel.parts)\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "        if depth > max_depth:\n",
        "            dirs[:] = []\n",
        "            continue\n",
        "\n",
        "        # Folders\n",
        "        for d in dirs:\n",
        "            if len(items) >= max_items:\n",
        "                truncated = True\n",
        "                dirs[:] = []\n",
        "                break\n",
        "            path_rel = str((current / d).relative_to(base))\n",
        "            items.append(\n",
        "                {\n",
        "                    \"path\": path_rel,\n",
        "                    \"type\": \"folder\",\n",
        "                    \"size\": None,\n",
        "                    \"depth\": depth + 1,\n",
        "                }\n",
        "            )\n",
        "\n",
        "        if truncated:\n",
        "            break\n",
        "\n",
        "        # Files\n",
        "        for f in files:\n",
        "            if len(items) >= max_items:\n",
        "                truncated = True\n",
        "                break\n",
        "            p = current / f\n",
        "            try:\n",
        "                size = p.stat().st_size\n",
        "            except FileNotFoundError:\n",
        "                size = None\n",
        "            path_rel = str(p.relative_to(base))\n",
        "            items.append(\n",
        "                {\n",
        "                    \"path\": path_rel,\n",
        "                    \"type\": \"file\",\n",
        "                    \"size\": size,\n",
        "                    \"depth\": depth + 1,\n",
        "                }\n",
        "            )\n",
        "\n",
        "        if truncated:\n",
        "            break\n",
        "\n",
        "    file_count = sum(1 for it in items if it[\"type\"] == \"file\")\n",
        "    folder_count = sum(1 for it in items if it[\"type\"] == \"folder\")\n",
        "\n",
        "    examples = items[: min(len(items), 12)]\n",
        "    bullet_lines = []\n",
        "    for it in examples:\n",
        "        size_str = f\"{it['size']} bytes\" if (it[\"size\"] is not None and it[\"type\"] == \"file\") else \"-\"\n",
        "        bullet_lines.append(f\"- {it['type']}: {it['path']} (size: {size_str})\")\n",
        "\n",
        "    if truncated:\n",
        "        bullet_lines.append(\"- (truncated summary; directory contains more items)\")\n",
        "\n",
        "    human_summary = textwrap.dedent(\n",
        "        f\"\"\"\n",
        "        Base directory: {base}\n",
        "        Number of folders: {folder_count}\n",
        "        Number of files: {file_count}\n",
        "\n",
        "        Example entries:\n",
        "        {os.linesep.join(bullet_lines)}\n",
        "        \"\"\"\n",
        "    ).strip()\n",
        "\n",
        "    return {\n",
        "        \"base_dir\": str(base),\n",
        "        \"items\": items,\n",
        "        \"truncated\": truncated,\n",
        "        \"human_summary\": human_summary,\n",
        "    }\n",
        "\n",
        "\n",
        "def plan_file_agent_actions(\n",
        "    base_dir: Union[str, Path],\n",
        "    user_goal: str,\n",
        "    dir_summary: Dict[str, Any],\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Use the LLM to create a file-operation plan (JSON) for the File System Agent.\n",
        "    \"\"\"\n",
        "    base_dir_str = str(Path(base_dir).resolve())\n",
        "    human_summary = dir_summary.get(\"human_summary\", \"\")\n",
        "\n",
        "    system_prompt = f\"\"\"\n",
        "You are a careful file-organization planning agent.\n",
        "\n",
        "You are given:\n",
        "- A base directory (the root within which you are allowed to operate).\n",
        "- A short summary of files/folders under that base directory.\n",
        "- A user goal describing how they want this directory organized.\n",
        "\n",
        "Your job is to return a JSON plan with safe actions to reorganize files/folders.\n",
        "\n",
        "SAFETY AND SCOPE:\n",
        "- You MUST operate only inside the base directory.\n",
        "- Use ONLY RELATIVE paths from the base directory. (Do NOT include the absolute base directory.)\n",
        "- Do NOT use absolute paths.\n",
        "- Do NOT reference any paths that are not mentioned or implied by the summary.\n",
        "- Prefer moving files into folders instead of deleting them.\n",
        "- For deletions, always use 'delete_soft' (moving into a trash folder) instead of permanent deletion.\n",
        "\n",
        "Allowed action types:\n",
        "\n",
        "1. \"mkdir\" (create folder)\n",
        "   params: {{\n",
        "     \"path\": \"relative/path/to/new/folder\"\n",
        "   }}\n",
        "\n",
        "2. \"move\" (move or rename a file/folder)\n",
        "   params: {{\n",
        "     \"src\": \"existing/path/from/base\",\n",
        "     \"dest\": \"new/path/from/base\"\n",
        "   }}\n",
        "\n",
        "3. \"delete_soft\" (soft delete by moving to trash folder)\n",
        "   params: {{\n",
        "     \"path\": \"existing/path/from/base\"\n",
        "   }}\n",
        "\n",
        "JSON FORMAT:\n",
        "Return ONLY valid JSON with this structure:\n",
        "\n",
        "{{\n",
        "  \"plan\": \"short natural language description of what you will do\",\n",
        "  \"actions\": [\n",
        "     {{\"id\": \"step1\", \"type\": \"mkdir\" | \"move\" | \"delete_soft\", \"params\": {{...}}}},\n",
        "     ...\n",
        "  ]\n",
        "}}\n",
        "\n",
        "If no changes are needed, return:\n",
        "{{\"plan\": \"no_changes_needed\", \"actions\": []}}\n",
        "\"\"\"\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "Base directory (absolute path): {base_dir_str}\n",
        "\n",
        "Directory summary:\n",
        "{human_summary}\n",
        "\n",
        "User goal:\n",
        "{user_goal}\n",
        "\n",
        "Remember:\n",
        "- Use ONLY relative paths (relative to the base directory).\n",
        "- Use only the allowed action types.\n",
        "- Use 'delete_soft' instead of actual deletion.\n",
        "Return JSON only.\n",
        "\"\"\"\n",
        "\n",
        "    plan = call_llm_json(\n",
        "        system_prompt=system_prompt,\n",
        "        user_prompt=user_prompt,\n",
        "        model=DEFAULT_FAST_MODEL,\n",
        "        max_tokens=800,\n",
        "        temperature=0.25,\n",
        "    )\n",
        "    return plan\n",
        "\n",
        "\n",
        "def validate_file_agent_actions(\n",
        "    base_dir: Union[str, Path],\n",
        "    plan: Dict[str, Any],\n",
        "    dir_summary: Dict[str, Any],\n",
        ") -> Tuple[List[Dict[str, Any]], List[str]]:\n",
        "    \"\"\"\n",
        "    Validate the file-agent actions before execution.\n",
        "\n",
        "    Ensures:\n",
        "    - Paths are relative and inside base_dir\n",
        "    - Sources exist when moving or soft-deleting\n",
        "    \"\"\"\n",
        "    base = Path(base_dir).resolve()\n",
        "    items = dir_summary.get(\"items\", [])\n",
        "    existing_paths = {it[\"path\"] for it in items}\n",
        "\n",
        "    actions = plan.get(\"actions\", []) if isinstance(plan, dict) else []\n",
        "    if not isinstance(actions, list):\n",
        "        actions = []\n",
        "\n",
        "    validated: List[Dict[str, Any]] = []\n",
        "    warnings: List[str] = []\n",
        "\n",
        "    for idx, action in enumerate(actions, start=1):\n",
        "        atype = action.get(\"type\")\n",
        "        params = action.get(\"params\", {}) or {}\n",
        "        aid = action.get(\"id\") or short_uid(\"file-step\")\n",
        "\n",
        "        def add_warning(msg: str) -> None:\n",
        "            warnings.append(f\"[action {idx} / {aid}] {msg}\")\n",
        "\n",
        "        def resolve_rel(p: str) -> Optional[Path]:\n",
        "            p = p.strip()\n",
        "            if not p:\n",
        "                add_warning(\"Empty path encountered.\")\n",
        "                return None\n",
        "            if os.path.isabs(p):\n",
        "                add_warning(f\"Absolute path not allowed: {p}\")\n",
        "                return None\n",
        "            try:\n",
        "                return safe_join(base, p)\n",
        "            except ValueError as ve:\n",
        "                add_warning(str(ve))\n",
        "                return None\n",
        "\n",
        "        if atype == \"mkdir\":\n",
        "            rel = str(params.get(\"path\", \"\")).strip()\n",
        "            if not rel:\n",
        "                add_warning(\"mkdir missing 'path'\")\n",
        "                continue\n",
        "            abs_path = resolve_rel(rel)\n",
        "            if abs_path is None:\n",
        "                continue\n",
        "            validated.append(\n",
        "                {\n",
        "                    \"id\": aid,\n",
        "                    \"type\": \"mkdir\",\n",
        "                    \"rel_path\": rel,\n",
        "                    \"abs_path\": str(abs_path),\n",
        "                    \"params\": {\"path\": rel},\n",
        "                }\n",
        "            )\n",
        "\n",
        "        elif atype == \"move\":\n",
        "            src_rel = str(params.get(\"src\", \"\")).strip()\n",
        "            dest_rel = str(params.get(\"dest\", \"\")).strip()\n",
        "            if not src_rel or not dest_rel:\n",
        "                add_warning(\"move requires both 'src' and 'dest'\")\n",
        "                continue\n",
        "            src_abs = resolve_rel(src_rel)\n",
        "            dest_abs = resolve_rel(dest_rel)\n",
        "            if src_abs is None or dest_abs is None:\n",
        "                continue\n",
        "            if src_rel not in existing_paths and not src_abs.exists():\n",
        "                add_warning(f\"Source path does not exist: {src_rel}\")\n",
        "                continue\n",
        "            validated.append(\n",
        "                {\n",
        "                    \"id\": aid,\n",
        "                    \"type\": \"move\",\n",
        "                    \"rel_src\": src_rel,\n",
        "                    \"rel_dest\": dest_rel,\n",
        "                    \"abs_src\": str(src_abs),\n",
        "                    \"abs_dest\": str(dest_abs),\n",
        "                    \"params\": {\"src\": src_rel, \"dest\": dest_rel},\n",
        "                }\n",
        "            )\n",
        "\n",
        "        elif atype == \"delete_soft\":\n",
        "            rel = str(params.get(\"path\", \"\")).strip()\n",
        "            if not rel:\n",
        "                add_warning(\"delete_soft missing 'path'\")\n",
        "                continue\n",
        "            abs_path = resolve_rel(rel)\n",
        "            if abs_path is None:\n",
        "                continue\n",
        "            if rel not in existing_paths and not abs_path.exists():\n",
        "                add_warning(f\"Path to delete_soft does not exist: {rel}\")\n",
        "                continue\n",
        "            validated.append(\n",
        "                {\n",
        "                    \"id\": aid,\n",
        "                    \"type\": \"delete_soft\",\n",
        "                    \"rel_path\": rel,\n",
        "                    \"abs_path\": str(abs_path),\n",
        "                    \"params\": {\"path\": rel},\n",
        "                }\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            add_warning(f\"Unknown action type: {atype!r}\")\n",
        "            continue\n",
        "\n",
        "    return validated, warnings\n",
        "\n",
        "\n",
        "def execute_file_agent_actions(\n",
        "    base_dir: Union[str, Path],\n",
        "    actions: List[Dict[str, Any]],\n",
        "    dry_run: bool = False,\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Execute validated file-agent actions with safety (soft-delete, no path traversal).\n",
        "    \"\"\"\n",
        "    base = Path(base_dir).resolve()\n",
        "    trash_dir = ensure_dir(base / FILE_AGENT_TRASH_DIR_NAME)\n",
        "\n",
        "    results: List[Dict[str, Any]] = []\n",
        "\n",
        "    for action in actions:\n",
        "        atype = action[\"type\"]\n",
        "        aid = action.get(\"id\", short_uid(\"file-step\"))\n",
        "        result: Dict[str, Any] = {\"id\": aid, \"type\": atype, \"status\": \"pending\"}\n",
        "\n",
        "        try:\n",
        "            if atype == \"mkdir\":\n",
        "                abs_path = Path(action[\"abs_path\"])\n",
        "                if dry_run:\n",
        "                    result[\"status\"] = \"ok (dry-run)\"\n",
        "                    result[\"message\"] = f\"Would create folder: {abs_path}\"\n",
        "                else:\n",
        "                    abs_path.mkdir(parents=True, exist_ok=True)\n",
        "                    result[\"status\"] = \"ok\"\n",
        "                    result[\"message\"] = f\"Created folder: {abs_path}\"\n",
        "\n",
        "            elif atype == \"move\":\n",
        "                abs_src = Path(action[\"abs_src\"])\n",
        "                abs_dest = Path(action[\"abs_dest\"])\n",
        "                if dry_run:\n",
        "                    result[\"status\"] = \"ok (dry-run)\"\n",
        "                    result[\"message\"] = f\"Would move {abs_src} -> {abs_dest}\"\n",
        "                else:\n",
        "                    abs_dest.parent.mkdir(parents=True, exist_ok=True)\n",
        "                    shutil.move(str(abs_src), str(abs_dest))\n",
        "                    result[\"status\"] = \"ok\"\n",
        "                    result[\"message\"] = f\"Moved {abs_src} -> {abs_dest}\"\n",
        "\n",
        "            elif atype == \"delete_soft\":\n",
        "                abs_path = Path(action[\"abs_path\"])\n",
        "                if dry_run:\n",
        "                    result[\"status\"] = \"ok (dry-run)\"\n",
        "                    result[\"message\"] = f\"Would soft-delete: {abs_path}\"\n",
        "                else:\n",
        "                    rel = abs_path.relative_to(base)\n",
        "                    trash_target = trash_dir / rel\n",
        "                    trash_target.parent.mkdir(parents=True, exist_ok=True)\n",
        "                    shutil.move(str(abs_path), str(trash_target))\n",
        "                    result[\"status\"] = \"ok\"\n",
        "                    result[\"message\"] = f\"Soft-deleted (moved to trash): {abs_path}\"\n",
        "\n",
        "            else:\n",
        "                result[\"status\"] = \"error\"\n",
        "                result[\"message\"] = f\"Unknown action type at execution: {atype}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            result[\"status\"] = \"error\"\n",
        "            result[\"message\"] = format_exception(e)\n",
        "\n",
        "        results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# ======================================================================================\n",
        "# General AI Chat: Finance-aware, with External Context\n",
        "# ======================================================================================\n",
        "\n",
        "TICKER_STOPWORDS = {\n",
        "    \"I\", \"A\", \"AN\", \"THE\", \"AND\", \"OR\", \"BUT\", \"FOR\", \"YOU\",\n",
        "    \"ARE\", \"IS\", \"AM\", \"ON\", \"OFF\", \"UP\", \"AS\", \"IT\", \"TO\",\n",
        "    \"DO\", \"BY\", \"OF\", \"IN\", \"ETF\", \"CEO\", \"CFO\", \"EPS\",\n",
        "}\n",
        "\n",
        "\n",
        "def detect_ticker_candidates(text: str, max_candidates: int = 3) -> List[str]:\n",
        "    \"\"\"\n",
        "    Very simple heuristic to detect ticker-like tokens (e.g., AAPL, TSLA).\n",
        "    \"\"\"\n",
        "    candidates = re.findall(r\"\\b[A-Z]{1,5}\\b\", text)\n",
        "    unique: List[str] = []\n",
        "    for c in candidates:\n",
        "        if c in TICKER_STOPWORDS:\n",
        "            continue\n",
        "        if c not in unique:\n",
        "            unique.append(c)\n",
        "        if len(unique) >= max_candidates:\n",
        "            break\n",
        "    return unique\n",
        "\n",
        "\n",
        "def build_finance_context_for_chat(\n",
        "    user_prompt: str,\n",
        "    use_external_feeds: bool,\n",
        "    period: str = \"6mo\",\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    If the user is asking about earnings or news for specific tickers,\n",
        "    fetch some data and news via yfinance + external feeds to give the LLM\n",
        "    extra context.\n",
        "    \"\"\"\n",
        "    lowered = user_prompt.lower()\n",
        "    keywords = [\"earnings\", \"q1\", \"q2\", \"q3\", \"q4\", \"results\", \"report\", \"guidance\", \"dividend\", \"news\"]\n",
        "    if not any(k in lowered for k in keywords):\n",
        "        return \"\"\n",
        "\n",
        "    tickers = detect_ticker_candidates(user_prompt, max_candidates=2)\n",
        "    if not tickers:\n",
        "        return \"\"\n",
        "\n",
        "    sections: List[str] = []\n",
        "    for t in tickers:\n",
        "        try:\n",
        "            price_change, hist, recs, news_text, info = fetch_stock_data(t, period)\n",
        "            if hist is None or hist.empty:\n",
        "                continue\n",
        "            last_close = hist[\"Close\"].iloc[-1]\n",
        "            last_close = float(last_close) if last_close is not None else None\n",
        "\n",
        "            pc_str = \"N/A\"\n",
        "            if price_change is not None:\n",
        "                pc_str = f\"{price_change:+.2f}%\"\n",
        "\n",
        "            company_name = info.get(\"shortName\") or info.get(\"longName\") or t\n",
        "\n",
        "            section_lines = [\n",
        "                f\"TICKER: {t}\",\n",
        "                f\"Company: {company_name}\",\n",
        "                f\"Approx. last close: {last_close:.2f}\" if last_close is not None else \"Approx. last close: N/A\",\n",
        "                f\"Recent price change over last bar: {pc_str}\",\n",
        "            ]\n",
        "\n",
        "            headlines = []\n",
        "            if news_text:\n",
        "                for h in news_text.split(\". \"):\n",
        "                    h = h.strip()\n",
        "                    if h:\n",
        "                        headlines.append(h)\n",
        "                        if len(headlines) >= 5:\n",
        "                            break\n",
        "\n",
        "            if headlines:\n",
        "                section_lines.append(\"Recent headlines (yfinance):\")\n",
        "                for h in headlines:\n",
        "                    section_lines.append(f\"- {h}\")\n",
        "            else:\n",
        "                section_lines.append(\"Recent headlines (yfinance): (none found or not available)\")\n",
        "\n",
        "            if use_external_feeds:\n",
        "                ext_ctx_obj = gather_external_market_context(t, extra_query=\"earnings\")\n",
        "                ext_text = ext_ctx_obj.get(\"combined_text\", \"\")\n",
        "                if ext_text:\n",
        "                    section_lines.append(\"\")\n",
        "                    section_lines.append(\"External context (NewsAPI/Reddit):\")\n",
        "                    for line in ext_text.splitlines():\n",
        "                        section_lines.append(line)\n",
        "\n",
        "            sections.append(\"\\n\".join(section_lines))\n",
        "        except Exception as e:\n",
        "            print(f\"[build_finance_context_for_chat] Error on {t}: {format_exception(e)}\", file=sys.stderr)\n",
        "            continue\n",
        "\n",
        "    if not sections:\n",
        "        return \"\"\n",
        "\n",
        "    return \"\\n\\n\" + \"\\n\\n\".join(sections)\n",
        "\n",
        "\n",
        "def general_ai_chat(\n",
        "    prompt: str,\n",
        "    detail_level: str = \"Medium\",\n",
        "    history: Optional[List[Dict[str, str]]] = None,\n",
        "    enable_finance_tools: bool = True,\n",
        "    enable_external_feeds: bool = True,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Enhanced general chat:\n",
        "    - Supports conversation history\n",
        "    - Configurable detail level (Short / Medium / Deep dive)\n",
        "    - Optionally uses finance tools (yfinance + Reddit/NewsAPI) for ticker-related\n",
        "      news/earnings questions\n",
        "    - Uses a richer prompt template to encourage structured answers\n",
        "\n",
        "    This does NOT magically give the LLM real-time awareness of everything,\n",
        "    but it *does* feed fresh context into the prompt for finance topics.\n",
        "    \"\"\"\n",
        "    detail_level_map = {\n",
        "        \"Short\": 350,\n",
        "        \"Medium\": 800,\n",
        "        \"Deep dive\": 1400,\n",
        "    }\n",
        "    max_tokens = detail_level_map.get(detail_level, 800)\n",
        "\n",
        "    finance_context = \"\"\n",
        "    if enable_finance_tools:\n",
        "        finance_context = build_finance_context_for_chat(\n",
        "            prompt,\n",
        "            use_external_feeds=enable_external_feeds,\n",
        "            period=\"6mo\",\n",
        "        )\n",
        "\n",
        "    system_prompt = textwrap.dedent(\"\"\"\n",
        "        You are an advanced assistant with strong skills in:\n",
        "        - financial markets and corporate earnings\n",
        "        - software engineering and debugging\n",
        "        - explaining complex ideas at different depth levels (short, medium, deep-dive)\n",
        "        - summarizing news and documents concisely\n",
        "\n",
        "        Rules:\n",
        "        - Think through problems step by step internally, but **do not** reveal chain-of-thought.\n",
        "        - Present only the final explanation, structured with:\n",
        "            * short sections with headings (when appropriate)\n",
        "            * bullet points for lists\n",
        "            * examples or analogies when they help understanding\n",
        "        - If you reference specific numeric info from the provided external data,\n",
        "          mention that it is approximate and may be time-limited.\n",
        "        - If you are unsure about current real-world facts (like very recent events),\n",
        "          say that explicitly instead of guessing.\n",
        "        - Avoid giving financial, legal, or medical advice. You may provide educational\n",
        "          information and general guidance only.\n",
        "    \"\"\").strip()\n",
        "\n",
        "    if finance_context:\n",
        "        user_prompt = textwrap.dedent(f\"\"\"\n",
        "        User question:\n",
        "        {prompt}\n",
        "\n",
        "        Additional financial data feed (from external providers like yfinance, Reddit, NewsAPI):\n",
        "        {finance_context}\n",
        "\n",
        "        Use this data feed where helpful, but do not overstate certainty.\n",
        "        \"\"\").strip()\n",
        "    else:\n",
        "        user_prompt = prompt\n",
        "\n",
        "    messages: List[Dict[str, str]] = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "\n",
        "    if history:\n",
        "        for msg in history[-10:]:\n",
        "            if \"role\" in msg and \"content\" in msg:\n",
        "                messages.append({\"role\": msg[\"role\"], \"content\": msg[\"content\"]})\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
        "\n",
        "    completion = _openai_chat_completion(\n",
        "        messages=messages,\n",
        "        model=DEFAULT_DETAILED_MODEL,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=0.7,\n",
        "        response_format=None,\n",
        "    )\n",
        "    answer = completion.choices[0].message.content.strip()\n",
        "    return answer\n",
        "\n",
        "\n",
        "# ======================================================================================\n",
        "# Streamlit UI: Setup & Session State\n",
        "# ======================================================================================\n",
        "\n",
        "st.set_page_config(\n",
        "    layout=\"wide\",\n",
        "    page_title=APP_NAME,\n",
        ")\n",
        "\n",
        "with st.sidebar:\n",
        "    st.markdown(f\"## ⚙️ Settings ({APP_VERSION})\")\n",
        "\n",
        "    analysis_depth = st.selectbox(\"Finance analysis depth\", [\"Quick\", \"Detailed\"], index=1)\n",
        "\n",
        "    use_llm_sentiment = st.checkbox(\n",
        "        \"Use LLM-based sentiment scoring\",\n",
        "        value=True,\n",
        "        help=\"If disabled, a deterministic demo score will be used for bullish/bearish sentiment.\",\n",
        "    )\n",
        "\n",
        "    enable_external_feeds_global = st.checkbox(\n",
        "        \"Use external feeds (Reddit + optional NewsAPI) where supported\",\n",
        "        value=True,\n",
        "        help=\"If OFF, app will ignore Reddit/NewsAPI and rely on yfinance only.\",\n",
        "    )\n",
        "\n",
        "    show_raw_finance_plan = st.checkbox(\n",
        "        \"Show raw finance agent plan (JSON)\",\n",
        "        value=False,\n",
        "        help=\"Displays the low-level JSON plan returned by the finance agent.\",\n",
        "    )\n",
        "\n",
        "    show_raw_file_plan = st.checkbox(\n",
        "        \"Show raw file agent plan (JSON)\",\n",
        "        value=False,\n",
        "        help=\"Displays the low-level JSON plan returned by the file agent.\",\n",
        "    )\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"### API Status\")\n",
        "    if OPENAI_API_KEY:\n",
        "        st.success(\"✅ OpenAI API key loaded\")\n",
        "    else:\n",
        "        st.error(\"❌ No API key (set OPENAI_API_KEY)\")\n",
        "\n",
        "    if enable_external_feeds_global:\n",
        "        st.caption(\n",
        "            \"External feeds enabled (Reddit search; NewsAPI if `NEWSAPI_KEY` is set). \"\n",
        "            \"All requests are best-effort and may fail silently under heavy rate-limits.\"\n",
        "        )\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.caption(\n",
        "        \"This application is for educational purposes only.\\n\"\n",
        "        \"**Nothing here is financial advice.**\"\n",
        "    )\n",
        "\n",
        "# Session state defaults\n",
        "if \"finance_analysis_done\" not in st.session_state:\n",
        "    st.session_state.finance_analysis_done = False\n",
        "\n",
        "if \"finance_stock_info\" not in st.session_state:\n",
        "    st.session_state.finance_stock_info = None\n",
        "\n",
        "if \"finance_agent_last_plan\" not in st.session_state:\n",
        "    st.session_state.finance_agent_last_plan = None\n",
        "\n",
        "if \"finance_agent_last_results\" not in st.session_state:\n",
        "    st.session_state.finance_agent_last_results = None\n",
        "\n",
        "if \"file_agent_last_summary\" not in st.session_state:\n",
        "    st.session_state.file_agent_last_summary = None\n",
        "\n",
        "if \"file_agent_last_plan\" not in st.session_state:\n",
        "    st.session_state.file_agent_last_plan = None\n",
        "\n",
        "if \"file_agent_last_validated\" not in st.session_state:\n",
        "    st.session_state.file_agent_last_validated = None\n",
        "\n",
        "if \"file_agent_last_exec_results\" not in st.session_state:\n",
        "    st.session_state.file_agent_last_exec_results = None\n",
        "\n",
        "if \"action_log\" not in st.session_state:\n",
        "    st.session_state.action_log = []\n",
        "\n",
        "if \"general_chat_history\" not in st.session_state:\n",
        "    st.session_state.general_chat_history: List[Dict[str, str]] = []\n",
        "\n",
        "if \"last_chat_response\" not in st.session_state:\n",
        "    st.session_state.last_chat_response = None\n",
        "\n",
        "# ======================================================================================\n",
        "# Tabs\n",
        "# ======================================================================================\n",
        "\n",
        "st.title(APP_NAME)\n",
        "st.subheader(\"LLM-driven narratives, live external context, and multi-agent automation.\")\n",
        "\n",
        "tab_finance, tab_finance_agent, tab_file_agent, tab_chat, tab_logs = st.tabs(\n",
        "    [\n",
        "        \"📈 Single Stock Explorer\",\n",
        "        \"🤖 Finance Agent\",\n",
        "        \"📂 File System Agent\",\n",
        "        \"💬 General AI Chat\",\n",
        "        \"📝 Action Logs\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ======================================================================================\n",
        "# Tab 4: General AI Chat (Richer, Finance-aware, External Feeds)\n",
        "# ======================================================================================\n",
        "\n",
        "with tab_chat:\n",
        "    st.subheader(\"General-purpose Chat with External Market Context\")\n",
        "\n",
        "    chat_detail_level = st.selectbox(\n",
        "        \"Answer detail level\",\n",
        "        [\"Short\", \"Medium\", \"Deep dive\"],\n",
        "        index=1,\n",
        "        help=\"Controls how long and detailed the answers will be.\",\n",
        "    )\n",
        "\n",
        "    chat_enable_finance_tools = st.checkbox(\n",
        "        \"Use finance tools (tickers, prices, earnings, etc.) when helpful\",\n",
        "        value=True,\n",
        "        help=\"If enabled, the assistant will look for ticker symbols and fetch basic price/news data.\",\n",
        "    )\n",
        "\n",
        "    chat_enable_external_feeds = st.checkbox(\n",
        "        \"Pull external feeds (Reddit + optional NewsAPI) for finance questions\",\n",
        "        value=enable_external_feeds_global,\n",
        "        help=\"If ON, the assistant may fetch Reddit posts and/or NewsAPI articles related to your question.\",\n",
        "    )\n",
        "\n",
        "    chat_prompt = st.text_area(\n",
        "        \"Ask me anything (finance, market events, Q3 earnings, coding, general topics):\",\n",
        "        height=140,\n",
        "        placeholder=\"Examples:\\n\"\n",
        "                    \"- Explain NVIDIA's Q3 earnings using recent news.\\n\"\n",
        "                    \"- Summarize what happened to TSLA last week.\\n\"\n",
        "                    \"- Help me debug this Python error.\\n\"\n",
        "                    \"- Compare AAPL and MSFT over the last year.\",\n",
        "    )\n",
        "\n",
        "    col_chat_buttons = st.columns(3)\n",
        "    with col_chat_buttons[0]:\n",
        "        chat_run = st.button(\"Send ✉️\")\n",
        "    with col_chat_buttons[1]:\n",
        "        chat_clear = st.button(\"Clear chat history\")\n",
        "    with col_chat_buttons[2]:\n",
        "        chat_clear_last = st.button(\"Clear last reply\")\n",
        "\n",
        "    if chat_clear:\n",
        "        st.session_state.general_chat_history = []\n",
        "        st.session_state.last_chat_response = None\n",
        "\n",
        "    if chat_clear_last and st.session_state.general_chat_history:\n",
        "        # Pop last assistant + possibly last user\n",
        "        if st.session_state.general_chat_history[-1][\"role\"] == \"assistant\":\n",
        "            st.session_state.general_chat_history.pop()\n",
        "        if st.session_state.general_chat_history and st.session_state.general_chat_history[-1][\"role\"] == \"user\":\n",
        "            st.session_state.general_chat_history.pop()\n",
        "        st.session_state.last_chat_response = None\n",
        "\n",
        "    if chat_run and chat_prompt.strip():\n",
        "        history = st.session_state.general_chat_history\n",
        "\n",
        "        # Append user message to history\n",
        "        history.append({\"role\": \"user\", \"content\": chat_prompt.strip()})\n",
        "\n",
        "        with st.spinner(\"Talking to the LLM with live market context...\"):\n",
        "            try:\n",
        "                response = general_ai_chat(\n",
        "                    prompt=chat_prompt.strip(),\n",
        "                    detail_level=chat_detail_level,\n",
        "                    history=history,\n",
        "                    enable_finance_tools=chat_enable_finance_tools,\n",
        "                    enable_external_feeds=chat_enable_external_feeds and enable_external_feeds_global,\n",
        "                )\n",
        "            except Exception as e:\n",
        "                response = (\n",
        "                    \"Could not generate a response due to an LLM error. \"\n",
        "                    f\"Internal error: {format_exception(e)}\"\n",
        "                )\n",
        "\n",
        "        history.append({\"role\": \"assistant\", \"content\": response})\n",
        "        st.session_state.general_chat_history = history\n",
        "        st.session_state.last_chat_response = response\n",
        "\n",
        "        # Log chat interaction\n",
        "        log_entry = {\n",
        "            \"time\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
        "            \"agent\": \"chat\",\n",
        "            \"detail_level\": chat_detail_level,\n",
        "            \"finance_tools_used\": chat_enable_finance_tools,\n",
        "            \"external_feeds_used\": chat_enable_external_feeds and enable_external_feeds_global,\n",
        "            \"user_message\": chat_prompt.strip(),\n",
        "            \"assistant_reply_preview\": response[:300],\n",
        "        }\n",
        "        st.session_state.action_log.append(log_entry)\n",
        "        append_jsonl(AGENT_LOG_FILE, log_entry)\n",
        "\n",
        "    # Render conversation\n",
        "    if st.session_state.general_chat_history:\n",
        "        st.markdown(\"### Conversation\")\n",
        "        for msg in st.session_state.general_chat_history:\n",
        "            if msg[\"role\"] == \"user\":\n",
        "                st.markdown(f\"**You:** {msg['content']}\")\n",
        "            elif msg[\"role\"] == \"assistant\":\n",
        "                st.markdown(f\"**Assistant:** {msg['content']}\")\n",
        "    else:\n",
        "        st.info(\"Start a conversation by typing a question or request above.\")\n",
        "\n",
        "# ======================================================================================\n",
        "# Tab 1: Single Stock Explorer (with external context and fixed charts)\n",
        "# ======================================================================================\n",
        "\n",
        "with tab_finance:\n",
        "    st.subheader(\"Single Stock Explorer\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        popular_stocks = [\"AAPL\", \"MSFT\", \"GOOGL\", \"TSLA\", \"AMZN\", \"NVDA\", \"META\"]\n",
        "        selected = st.selectbox(\"Select a popular stock ticker:\", popular_stocks)\n",
        "        custom_ticker = st.text_input(\n",
        "            \"Or type any other ticker (overrides selection above):\",\n",
        "            value=\"\",\n",
        "            placeholder=\"e.g. NFLX\",\n",
        "        )\n",
        "        ticker_input = (custom_ticker or selected).upper().strip()\n",
        "\n",
        "    with col2:\n",
        "        time_period = st.selectbox(\n",
        "            \"Select chart time period:\",\n",
        "            (\"1d\", \"5d\", \"1mo\", \"3mo\", \"6mo\", \"1y\", \"2y\", \"5y\", \"10y\", \"ytd\", \"max\"),\n",
        "            index=2,\n",
        "        )\n",
        "\n",
        "    analyze_col, clear_col = st.columns([1, 1])\n",
        "\n",
        "    with analyze_col:\n",
        "        analyze_clicked = st.button(\"🔍 Analyze Stock\", type=\"primary\")\n",
        "    with clear_col:\n",
        "        clear_clicked = st.button(\"❌ Clear Analysis\")\n",
        "\n",
        "    if clear_clicked:\n",
        "        st.session_state.finance_analysis_done = False\n",
        "        st.session_state.finance_stock_info = None\n",
        "        st.rerun()\n",
        "\n",
        "    if analyze_clicked:\n",
        "        if not ticker_input:\n",
        "            st.warning(\"Please enter or select a stock ticker.\")\n",
        "        else:\n",
        "            with st.spinner(f\"Fetching data and generating narrative for {ticker_input}...\"):\n",
        "                price_change, hist, recommendations, news_text, info = fetch_stock_data(\n",
        "                    ticker_input, time_period\n",
        "                )\n",
        "\n",
        "                if hist is not None and not hist.empty:\n",
        "                    # External context (Reddit + NewsAPI + additional yfinance news)\n",
        "                    external_ctx_obj = (\n",
        "                        gather_external_market_context(ticker_input)\n",
        "                        if enable_external_feeds_global\n",
        "                        else {\"combined_text\": \"\", \"sources\": {}}\n",
        "                    )\n",
        "                    external_ctx_text = external_ctx_obj.get(\"combined_text\", \"\")\n",
        "\n",
        "                    if use_llm_sentiment:\n",
        "                        bullish, bearish, sentiment_summary = analyze_sentiment_with_llm(\n",
        "                            ticker_input,\n",
        "                            base_news_text=news_text or \"\",\n",
        "                            external_context=external_ctx_text,\n",
        "                        )\n",
        "                    else:\n",
        "                        bullish, bearish = mock_sentiment_score(ticker_input)\n",
        "                        sentiment_summary = (\n",
        "                            \"Deterministic demo sentiment score (LLM sentiment disabled).\"\n",
        "                        )\n",
        "\n",
        "                    narrative = generate_narrative(\n",
        "                        ticker=ticker_input,\n",
        "                        price_change=price_change,\n",
        "                        bullish=bullish,\n",
        "                        bearish=bearish,\n",
        "                        base_news_text=news_text,\n",
        "                        recommendations_data=recommendations,\n",
        "                        external_context_text=external_ctx_text,\n",
        "                    )\n",
        "\n",
        "                    st.session_state.finance_analysis_done = True\n",
        "                    st.session_state.finance_stock_info = {\n",
        "                        \"ticker\": ticker_input,\n",
        "                        \"price_change\": price_change,\n",
        "                        \"bullish\": bullish,\n",
        "                        \"bearish\": bearish,\n",
        "                        \"sentiment_summary\": sentiment_summary,\n",
        "                        \"narrative\": narrative,\n",
        "                        \"hist\": hist,\n",
        "                        \"recommendations\": recommendations,\n",
        "                        \"news_text\": news_text,\n",
        "                        \"info\": info,\n",
        "                        \"period\": time_period,\n",
        "                        \"external_context\": external_ctx_text,\n",
        "                    }\n",
        "\n",
        "                    # Log this single-stock analysis as an action\n",
        "                    log_entry = {\n",
        "                        \"time\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
        "                        \"agent\": \"finance-single\",\n",
        "                        \"ticker\": ticker_input,\n",
        "                        \"period\": time_period,\n",
        "                        \"price_change\": price_change,\n",
        "                        \"bullish\": bullish,\n",
        "                        \"bearish\": bearish,\n",
        "                        \"external_feeds_used\": enable_external_feeds_global,\n",
        "                    }\n",
        "                    st.session_state.action_log.append(log_entry)\n",
        "                    append_jsonl(AGENT_LOG_FILE, log_entry)\n",
        "\n",
        "                    st.rerun()\n",
        "                else:\n",
        "                    st.error(\"No price history found for that ticker/time period.\")\n",
        "\n",
        "    if st.session_state.finance_analysis_done and st.session_state.finance_stock_info:\n",
        "        info_data = st.session_state.finance_stock_info\n",
        "        ticker = info_data[\"ticker\"]\n",
        "        period = info_data.get(\"period\", time_period)\n",
        "\n",
        "        st.markdown(f\"### Analysis for `{ticker}`\")\n",
        "\n",
        "        metric_col1, metric_col2, metric_col3 = st.columns(3)\n",
        "        with metric_col1:\n",
        "            pc = info_data[\"price_change\"]\n",
        "            pc_str = f\"{pc:+.2f}%\" if pc is not None else \"N/A\"\n",
        "            st.metric(label=\"Price Change (Last Bar)\", value=pc_str)\n",
        "        with metric_col2:\n",
        "            st.metric(\n",
        "                label=\"Sentiment\",\n",
        "                value=f\"📈 {info_data['bullish']}% Bullish\\n📉 {info_data['bearish']}% Bearish\",\n",
        "            )\n",
        "        with metric_col3:\n",
        "            st.caption(\"Sentiment explanation:\")\n",
        "            st.write(info_data.get(\"sentiment_summary\", \"\"))\n",
        "\n",
        "        st.markdown(\"#### Additional Stock Information\")\n",
        "        info_buttons_col1, info_buttons_col2, info_buttons_col3 = st.columns(3)\n",
        "\n",
        "        with info_buttons_col1:\n",
        "            if st.button(\"Show Market Cap\"):\n",
        "                market_cap = info_data[\"info\"].get(\"marketCap\")\n",
        "                if market_cap is not None:\n",
        "                    st.write(f\"Market Cap: ${market_cap:,.0f}\")\n",
        "                else:\n",
        "                    st.write(\"Market Cap: N/A\")\n",
        "\n",
        "        with info_buttons_col2:\n",
        "            if st.button(\"Show Dividend Yield\"):\n",
        "                dividend_yield = info_data[\"info\"].get(\"dividendYield\")\n",
        "                if dividend_yield is not None:\n",
        "                    st.write(f\"Dividend Yield: {dividend_yield:.2%}\")\n",
        "                else:\n",
        "                    st.write(\"Dividend Yield: N/A\")\n",
        "\n",
        "        with info_buttons_col3:\n",
        "            if st.button(\"Show P/E Ratio\"):\n",
        "                pe_ratio = info_data[\"info\"].get(\"trailingPE\")\n",
        "                if pe_ratio is not None:\n",
        "                    st.write(f\"P/E Ratio: {pe_ratio:.2f}\")\n",
        "                else:\n",
        "                    st.write(\"P/E Ratio: N/A\")\n",
        "\n",
        "        st.markdown(\"#### Market Narrative\")\n",
        "        st.write(info_data[\"narrative\"])\n",
        "\n",
        "        st.markdown(f\"#### {ticker} Price Chart ({period})\")\n",
        "\n",
        "        # Ensure chart is using time index correctly\n",
        "        hist = info_data[\"hist\"].copy()\n",
        "        hist.sort_index(inplace=True)\n",
        "        close_series = hist[\"Close\"].rename(ticker)\n",
        "        st.line_chart(close_series)\n",
        "\n",
        "        st.markdown(\"#### Analyst Recommendations (Latest)\")\n",
        "        recommendations = info_data[\"recommendations\"]\n",
        "        if recommendations is not None and not recommendations.empty:\n",
        "            latest_rec = recommendations.iloc[0]\n",
        "            st.write(\n",
        "                f\"Strong Buy: {latest_rec.get('strongBuy', 'N/A')}, \"\n",
        "                f\"Buy: {latest_rec.get('buy', 'N/A')}, \"\n",
        "                f\"Hold: {latest_rec.get('hold', 'N/A')}, \"\n",
        "                f\"Sell: {latest_rec.get('sell', 'N/A')}, \"\n",
        "                f\"Strong Sell: {latest_rec.get('strongSell', 'N/A')}\"\n",
        "            )\n",
        "        else:\n",
        "            st.write(\"No recent analyst recommendations available.\")\n",
        "\n",
        "        st.markdown(\"#### Recent News Headlines (yfinance)\")\n",
        "        news_text = info_data[\"news_text\"]\n",
        "        if news_text:\n",
        "            for headline in news_text.split(\". \"):\n",
        "                h = headline.strip()\n",
        "                if h:\n",
        "                    st.write(f\"- {h}\")\n",
        "        else:\n",
        "            st.write(\"No recent news available from yfinance.\")\n",
        "\n",
        "        if info_data.get(\"external_context\"):\n",
        "            st.markdown(\"#### External Context (Reddit + optional NewsAPI)\")\n",
        "            with st.expander(\"Show external context used for the narrative\"):\n",
        "                st.text(info_data[\"external_context\"])\n",
        "\n",
        "# ======================================================================================\n",
        "# Tab 2: Finance Agent\n",
        "# ======================================================================================\n",
        "\n",
        "with tab_finance_agent:\n",
        "    st.subheader(\"Finance Agent: Natural-language Task Runner\")\n",
        "\n",
        "    st.markdown(\n",
        "        \"Describe a task and let the agent plan and execute it using live market data \"\n",
        "        \"and external context.\\n\\n\"\n",
        "        \"**Examples:**\\n\"\n",
        "        \"- *\\\"Compare TSLA and F with performance over the last year\\\"*\\n\"\n",
        "        \"- *\\\"Build a $5,000 balanced portfolio using AAPL, MSFT, and NVDA\\\"*\\n\"\n",
        "        \"- *\\\"Analyze NVDA Q3 earnings\\\"* (the agent may use external news feeds)\\n\"\n",
        "    )\n",
        "\n",
        "    agent_goal = st.text_area(\n",
        "        \"What do you want the finance agent to do?\",\n",
        "        height=120,\n",
        "        placeholder=\"e.g. Build a $10,000 aggressive portfolio with TSLA, NVDA, and AMD\",\n",
        "    )\n",
        "\n",
        "    agent_col1, agent_col2 = st.columns([1, 1])\n",
        "    with agent_col1:\n",
        "        run_agent = st.button(\"🚀 Plan & Execute Finance Task\", type=\"primary\")\n",
        "    with agent_col2:\n",
        "        clear_agent = st.button(\"🧹 Clear Finance Agent Output\")\n",
        "\n",
        "    if clear_agent:\n",
        "        st.session_state.finance_agent_last_plan = None\n",
        "        st.session_state.finance_agent_last_results = None\n",
        "        st.rerun()\n",
        "\n",
        "    if run_agent and agent_goal.strip():\n",
        "        with st.spinner(\"Letting the finance agent plan your task...\"):\n",
        "            try:\n",
        "                plan = plan_finance_agent(agent_goal.strip())\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error calling planner: {format_exception(e)}\")\n",
        "                plan = {\"plan\": \"error\", \"actions\": [], \"error\": str(e)}\n",
        "\n",
        "            st.session_state.finance_agent_last_plan = plan\n",
        "            try:\n",
        "                results = execute_finance_agent_actions(plan, use_llm_sentiment=use_llm_sentiment)\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error executing finance agent actions: {format_exception(e)}\")\n",
        "                results = [{\"type\": \"error\", \"error\": str(e)}]\n",
        "\n",
        "            st.session_state.finance_agent_last_results = results\n",
        "\n",
        "            log_entry = {\n",
        "                \"time\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
        "                \"agent\": \"finance-agent\",\n",
        "                \"goal\": agent_goal.strip(),\n",
        "                \"plan_summary\": plan.get(\"plan\", \"\"),\n",
        "                \"actions\": [a.get(\"type\", \"unknown\") for a in plan.get(\"actions\", [])]\n",
        "                if isinstance(plan, dict)\n",
        "                else [],\n",
        "            }\n",
        "            st.session_state.action_log.append(log_entry)\n",
        "            append_jsonl(AGENT_LOG_FILE, log_entry)\n",
        "\n",
        "    plan = st.session_state.finance_agent_last_plan\n",
        "    results = st.session_state.finance_agent_last_results\n",
        "\n",
        "    if plan:\n",
        "        st.markdown(\"### Finance Agent Plan\")\n",
        "        st.write(plan.get(\"plan\", \"No plan description provided.\"))\n",
        "\n",
        "        if show_raw_finance_plan:\n",
        "            st.markdown(\"##### Raw Plan (JSON)\")\n",
        "            st.json(plan)\n",
        "\n",
        "    if results:\n",
        "        st.markdown(\"### Finance Agent Results\")\n",
        "\n",
        "        for idx, res in enumerate(results, start=1):\n",
        "            rtype = res.get(\"type\")\n",
        "            st.markdown(f\"#### Step {idx}: `{rtype}`\")\n",
        "\n",
        "            if rtype == \"fetch_stock\":\n",
        "                ticker = res[\"ticker\"]\n",
        "                period = res[\"period\"]\n",
        "                col_a, col_b = st.columns(2)\n",
        "                with col_a:\n",
        "                    pc = res[\"price_change\"]\n",
        "                    pc_str = f\"{pc:+.2f}%\" if pc is not None else \"N/A\"\n",
        "                    st.metric(\n",
        "                        label=f\"{ticker} Price Change ({period})\",\n",
        "                        value=pc_str,\n",
        "                    )\n",
        "                with col_b:\n",
        "                    st.metric(\n",
        "                        label=\"Sentiment\",\n",
        "                        value=f\"📈 {res['bullish']}% Bullish / 📉 {res['bearish']}% Bearish\",\n",
        "                    )\n",
        "                    st.caption(res.get(\"sentiment_summary\", \"\"))\n",
        "\n",
        "                hist = res[\"hist\"].copy()\n",
        "                hist.sort_index(inplace=True)\n",
        "                st.line_chart(hist[\"Close\"].rename(ticker))\n",
        "\n",
        "                if analysis_depth == \"Detailed\":\n",
        "                    st.markdown(\"**Narrative:**\")\n",
        "                    st.write(res[\"narrative\"])\n",
        "\n",
        "                if res.get(\"external_context\"):\n",
        "                    with st.expander(\"External context used (Reddit + optional NewsAPI)\"):\n",
        "                        st.text(res[\"external_context\"])\n",
        "\n",
        "            elif rtype == \"compare_stocks\":\n",
        "                tickers = res.get(\"tickers\", [])\n",
        "                st.write(f\"Comparing: {', '.join(tickers)} over {res.get('period')}\")\n",
        "                returns = res.get(\"returns\", {})\n",
        "                if returns:\n",
        "                    pretty = {t: f\"{r:+.2f}%\" for t, r in returns.items()}\n",
        "                    st.write(pretty)\n",
        "                df_norm = res.get(\"normalized_prices\", pd.DataFrame())\n",
        "                if not df_norm.empty:\n",
        "                    st.line_chart(df_norm)\n",
        "                st.write(res.get(\"analysis\", \"\"))\n",
        "\n",
        "            elif rtype == \"build_portfolio\":\n",
        "                st.write(f\"Capital: ${res.get('capital', 0):,.2f}\")\n",
        "                st.write(f\"Risk level: {res.get('risk_level')}\")\n",
        "                allocations = res.get(\"allocations\", [])\n",
        "                if allocations:\n",
        "                    df_alloc = pd.DataFrame(allocations)\n",
        "                    st.dataframe(df_alloc, use_container_width=True)\n",
        "                st.write(f\"Unallocated cash: ${res.get('cash_left', 0):,.2f}\")\n",
        "                st.write(res.get(\"explanation\", \"\"))\n",
        "\n",
        "            elif rtype == \"external_news_only\":\n",
        "                ticker = res.get(\"ticker\")\n",
        "                query = res.get(\"query\")\n",
        "                st.write(f\"External news-focused analysis for {ticker} (query: {query})\")\n",
        "                st.metric(\n",
        "                    label=\"Sentiment\",\n",
        "                    value=f\"📈 {res['bullish']}% Bullish / 📉 {res['bearish']}% Bearish\",\n",
        "                )\n",
        "                st.caption(res.get(\"sentiment_summary\", \"\"))\n",
        "                st.write(res.get(\"narrative\", \"No narrative.\"))\n",
        "                if res.get(\"external_context\"):\n",
        "                    with st.expander(\"External context used\"):\n",
        "                        st.text(res[\"external_context\"])\n",
        "\n",
        "            elif rtype == \"error\":\n",
        "                st.error(res.get(\"error\", \"Unknown error\"))\n",
        "                if \"raw_action\" in res:\n",
        "                    with st.expander(\"Show raw action\"):\n",
        "                        st.json(res[\"raw_action\"])\n",
        "\n",
        "            else:\n",
        "                st.warning(f\"Unrecognized result type: {rtype}\")\n",
        "                with st.expander(\"Show raw result\"):\n",
        "                    st.json(res)\n",
        "\n",
        "# ======================================================================================\n",
        "# Tab 3: File System Agent\n",
        "# ======================================================================================\n",
        "\n",
        "with tab_file_agent:\n",
        "    st.subheader(\"File System Agent: Local File Organizer\")\n",
        "\n",
        "    st.markdown(\n",
        "        \"This agent operates on directories in your Colab/Streamlit environment.\\n\\n\"\n",
        "        \"**Capabilities:**\\n\"\n",
        "        \"- Summarize a directory and show files/folders.\\n\"\n",
        "        \"- Use an LLM to plan moves, renames, and folder creation.\\n\"\n",
        "        \"- Soft-delete files by moving them into a trash folder.\\n\"\n",
        "        \"- Validate and execute the plan with safety checks and explicit confirmation.\\n\\n\"\n",
        "        \"**Important:** The agent only works inside the base directory you specify. \"\n",
        "        \"Paths are checked so the agent cannot escape that directory.\"\n",
        "    )\n",
        "\n",
        "    default_base_dir = str(ROOT_DIR)\n",
        "    base_dir_input = st.text_input(\n",
        "        \"Base directory (the agent's sandbox root):\",\n",
        "        value=default_base_dir,\n",
        "        help=\"The file agent will only operate inside this directory.\",\n",
        "    )\n",
        "\n",
        "    col_scan, col_clear = st.columns([1, 1])\n",
        "    with col_scan:\n",
        "        scan_clicked = st.button(\"🔎 Scan Directory\")\n",
        "    with col_clear:\n",
        "        clear_file_agent = st.button(\"🧹 Clear File Agent State\")\n",
        "\n",
        "    if clear_file_agent:\n",
        "        st.session_state.file_agent_last_summary = None\n",
        "        st.session_state.file_agent_last_plan = None\n",
        "        st.session_state.file_agent_last_validated = None\n",
        "        st.session_state.file_agent_last_exec_results = None\n",
        "        st.rerun()\n",
        "\n",
        "    if scan_clicked:\n",
        "        try:\n",
        "            with st.spinner(\"Summarizing directory contents...\"):\n",
        "                summary = summarize_directory(base_dir_input)\n",
        "                st.session_state.file_agent_last_summary = summary\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error summarizing directory: {format_exception(e)}\")\n",
        "\n",
        "    summary = st.session_state.file_agent_last_summary\n",
        "\n",
        "    if summary:\n",
        "        st.markdown(\"### Directory Summary\")\n",
        "        st.write(f\"**Base directory:** `{summary['base_dir']}`\")\n",
        "        st.write(summary[\"human_summary\"])\n",
        "\n",
        "        items_df = pd.DataFrame(summary[\"items\"])\n",
        "        if not items_df.empty:\n",
        "            st.markdown(\"#### Items (subset)\")\n",
        "            st.dataframe(items_df.head(200), use_container_width=True)\n",
        "        else:\n",
        "            st.info(\"No items found under this directory (within the configured depth).\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"### Plan File Operations with the Agent\")\n",
        "\n",
        "        file_agent_goal = st.text_area(\n",
        "            \"Describe how you want to organize this directory:\",\n",
        "            height=120,\n",
        "            placeholder=\"e.g. Group PDFs into a 'docs' folder, images into 'images', and move old logs into 'archive'.\",\n",
        "        )\n",
        "\n",
        "        col_plan, col_validate = st.columns([1, 1])\n",
        "        with col_plan:\n",
        "            plan_file_agent = st.button(\"🧠 Generate File-Agent Plan\", type=\"primary\")\n",
        "        with col_validate:\n",
        "            validate_file_agent_btn = st.button(\"✅ Validate Plan\")\n",
        "\n",
        "        if plan_file_agent and file_agent_goal.strip():\n",
        "            with st.spinner(\"Asking the LLM to design a file-operation plan...\"):\n",
        "                try:\n",
        "                    plan = plan_file_agent_actions(\n",
        "                        base_dir=summary[\"base_dir\"],\n",
        "                        user_goal=file_agent_goal.strip(),\n",
        "                        dir_summary=summary,\n",
        "                    )\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Error generating file-agent plan: {format_exception(e)}\")\n",
        "                    plan = {\"plan\": \"error\", \"actions\": [], \"error\": str(e)}\n",
        "\n",
        "                st.session_state.file_agent_last_plan = plan\n",
        "                st.session_state.file_agent_last_validated = None\n",
        "                st.session_state.file_agent_last_exec_results = None\n",
        "\n",
        "                log_entry = {\n",
        "                    \"time\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
        "                    \"agent\": \"file-agent\",\n",
        "                    \"goal\": file_agent_goal.strip(),\n",
        "                    \"plan_summary\": plan.get(\"plan\", \"\"),\n",
        "                    \"actions\": [a.get(\"type\", \"unknown\") for a in plan.get(\"actions\", [])]\n",
        "                    if isinstance(plan, dict)\n",
        "                    else [],\n",
        "                }\n",
        "                st.session_state.action_log.append(log_entry)\n",
        "                append_jsonl(AGENT_LOG_FILE, log_entry)\n",
        "\n",
        "        plan = st.session_state.file_agent_last_plan\n",
        "\n",
        "        if plan:\n",
        "            st.markdown(\"### File-Agent Plan\")\n",
        "            st.write(plan.get(\"plan\", \"No plan description provided.\"))\n",
        "\n",
        "            if show_raw_file_plan:\n",
        "                st.markdown(\"##### Raw File-Agent Plan (JSON)\")\n",
        "                st.json(plan)\n",
        "\n",
        "        if validate_file_agent_btn and plan:\n",
        "            with st.spinner(\"Validating plan and checking paths...\"):\n",
        "                try:\n",
        "                    validated_actions, warnings = validate_file_agent_actions(\n",
        "                        base_dir=summary[\"base_dir\"],\n",
        "                        plan=plan,\n",
        "                        dir_summary=summary,\n",
        "                    )\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Error validating file-agent plan: {format_exception(e)}\")\n",
        "                    validated_actions, warnings = [], []\n",
        "\n",
        "                st.session_state.file_agent_last_validated = validated_actions\n",
        "\n",
        "                if warnings:\n",
        "                    st.markdown(\"#### Validation Warnings\")\n",
        "                    for w in warnings:\n",
        "                        st.warning(w)\n",
        "                else:\n",
        "                    st.success(\"No validation warnings; actions look structurally safe.\")\n",
        "\n",
        "        validated_actions = st.session_state.file_agent_last_validated\n",
        "\n",
        "        if validated_actions:\n",
        "            st.markdown(\"### Validated Actions\")\n",
        "\n",
        "            readable_rows = []\n",
        "            for a in validated_actions:\n",
        "                if a[\"type\"] == \"mkdir\":\n",
        "                    readable_rows.append(\n",
        "                        {\n",
        "                            \"id\": a[\"id\"],\n",
        "                            \"type\": \"mkdir\",\n",
        "                            \"details\": f\"Create folder '{a['rel_path']}'\",\n",
        "                        }\n",
        "                    )\n",
        "                elif a[\"type\"] == \"move\":\n",
        "                    readable_rows.append(\n",
        "                        {\n",
        "                            \"id\": a[\"id\"],\n",
        "                            \"type\": \"move\",\n",
        "                            \"details\": f\"Move '{a['rel_src']}' -> '{a['rel_dest']}'\",\n",
        "                        }\n",
        "                    )\n",
        "                elif a[\"type\"] == \"delete_soft\":\n",
        "                    readable_rows.append(\n",
        "                        {\n",
        "                            \"id\": a[\"id\"],\n",
        "                            \"type\": \"delete_soft\",\n",
        "                            \"details\": f\"Soft-delete '{a['rel_path']}' (move to trash)\",\n",
        "                        }\n",
        "                    )\n",
        "                else:\n",
        "                    readable_rows.append(\n",
        "                        {\n",
        "                            \"id\": a[\"id\"],\n",
        "                            \"type\": a[\"type\"],\n",
        "                            \"details\": \"Unknown action type\",\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "            readable_df = pd.DataFrame(readable_rows)\n",
        "            st.dataframe(readable_df, use_container_width=True)\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\"### Execute File-Agent Plan\")\n",
        "\n",
        "            col_exec1, col_exec2 = st.columns([1, 1])\n",
        "            with col_exec1:\n",
        "                confirm_checkbox = st.checkbox(\n",
        "                    \"I understand this will modify files/folders inside the base directory.\",\n",
        "                    value=False,\n",
        "                )\n",
        "            with col_exec2:\n",
        "                dry_run_mode = st.checkbox(\n",
        "                    \"Dry-run mode (simulate only, no actual changes)\",\n",
        "                    value=True,\n",
        "                    help=\"Recommended to preview actions before actual execution.\",\n",
        "                )\n",
        "\n",
        "            exec_clicked = st.button(\"⚙️ Execute Plan\")\n",
        "\n",
        "            if exec_clicked:\n",
        "                if not confirm_checkbox and not dry_run_mode:\n",
        "                    st.error(\n",
        "                        \"You must confirm that you understand the plan will modify files/folders \"\n",
        "                        \"if you turn off dry-run mode.\"\n",
        "                    )\n",
        "                else:\n",
        "                    with st.spinner(\n",
        "                        \"Executing file-agent actions (respecting dry-run mode setting)...\"\n",
        "                    ):\n",
        "                        try:\n",
        "                            exec_results = execute_file_agent_actions(\n",
        "                                base_dir=summary[\"base_dir\"],\n",
        "                                actions=validated_actions,\n",
        "                                dry_run=dry_run_mode,\n",
        "                            )\n",
        "                        except Exception as e:\n",
        "                            st.error(f\"Error executing file-agent actions: {format_exception(e)}\")\n",
        "                            exec_results = []\n",
        "\n",
        "                        st.session_state.file_agent_last_exec_results = exec_results\n",
        "\n",
        "                        exec_log_entry = {\n",
        "                            \"time\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
        "                            \"agent\": \"file-agent-exec\",\n",
        "                            \"goal\": file_agent_goal.strip() if file_agent_goal else \"\",\n",
        "                            \"plan_summary\": plan.get(\"plan\", \"\"),\n",
        "                            \"dry_run\": dry_run_mode,\n",
        "                            \"exec_results\": exec_results,\n",
        "                        }\n",
        "                        st.session_state.action_log.append(exec_log_entry)\n",
        "                        append_jsonl(AGENT_LOG_FILE, exec_log_entry)\n",
        "\n",
        "            exec_results = st.session_state.file_agent_last_exec_results\n",
        "            if exec_results:\n",
        "                st.markdown(\"#### Execution Results\")\n",
        "                for r in exec_results:\n",
        "                    status = r.get(\"status\", \"unknown\")\n",
        "                    msg = r.get(\"message\", \"\")\n",
        "                    if status.startswith(\"ok\"):\n",
        "                        st.success(f\"[{r['type']}] {msg}\")\n",
        "                    elif status == \"pending\":\n",
        "                        st.info(f\"[{r['type']}] {msg}\")\n",
        "                    else:\n",
        "                        st.error(f\"[{r['type']}] {msg}\")\n",
        "\n",
        "                if not dry_run_mode:\n",
        "                    st.info(\n",
        "                        \"If you executed the plan (non-dry-run), you may click **Scan Directory** \"\n",
        "                        \"again to see the updated structure.\"\n",
        "                    )\n",
        "\n",
        "    else:\n",
        "        st.info(\n",
        "            \"Scan a directory first to see its contents and allow the file agent \"\n",
        "            \"to plan operations.\"\n",
        "        )\n",
        "\n",
        "# ======================================================================================\n",
        "# Tab 5: Action Logs\n",
        "# ======================================================================================\n",
        "\n",
        "with tab_logs:\n",
        "    st.subheader(\"Agent Action Logs\")\n",
        "\n",
        "    st.markdown(\n",
        "        \"This section shows actions taken by the Finance Agent, File Agent, General Chat, \"\n",
        "        \"and Single Stock Explorer.\\n\\n\"\n",
        "        \"- The **session log** shows actions logged in this Streamlit session.\\n\"\n",
        "        \"- The **persistent log** reads from `agent_logs/agent_actions.jsonl` (if present).\"\n",
        "    )\n",
        "\n",
        "    st.markdown(\"### Session Log (In-Memory)\")\n",
        "    if st.session_state.action_log:\n",
        "        df_session_log = pd.DataFrame(st.session_state.action_log)\n",
        "        st.dataframe(df_session_log, use_container_width=True)\n",
        "    else:\n",
        "        st.write(\"No agent actions logged in this session yet.\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"### Persistent Log (agent_logs/agent_actions.jsonl)\")\n",
        "\n",
        "    persistent_records = load_jsonl(AGENT_LOG_FILE, max_lines=2000)\n",
        "    if persistent_records:\n",
        "        df_persist = pd.DataFrame(persistent_records)\n",
        "        st.dataframe(df_persist, use_container_width=True)\n",
        "    else:\n",
        "        st.write(\"No persistent logs found yet.\")\n",
        "\n",
        "    st.caption(\n",
        "        \"Logs are stored as JSONL for easy post-hoc analysis or debugging. \"\n",
        "        \"You can download the `agent_logs` directory from your Colab workspace.\"\n",
        "    )\n",
        "\n",
        "# ======================================================================================\n",
        "# Footer\n",
        "# ======================================================================================\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.info(\n",
        "    \"This application demonstrates a full AI Agent pipeline for CS4680 (previously 4990):\\n\"\n",
        "    \"- LLM integration module with retry + JSON/text response helpers\\n\"\n",
        "    \"- Action interpreter & executor (Finance and File System agents)\\n\"\n",
        "    \"- External data ingestion from yfinance, Reddit, and optional NewsAPI\\n\"\n",
        "    \"- GUI interface with feedback and error messages\\n\"\n",
        "    \"- Safety checks (path validation, confirmations, dry-run mode)\\n\"\n",
        "    \"- Logging of all actions for auditability\\n\\n\"\n",
        "    \"Nothing here is financial advice. Use this as a learning tool.\"\n",
        ")\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    }
  ]
}