# Heart Disease Prediction Analysis

## Problem Definition
The goal of this analysis is to build classification models to predict the presence of heart disease based on patient health data. A key focus is on achieving high **Recall** for the positive class (indicating heart disease) to minimize false negatives, as missing a diagnosis can have serious consequences.

## Exploratory Data Analysis (EDA)
### Univariate Analysis
Distributions of numerical features (age, trestbps, chol, thalach, oldpeak) were visualized using histograms. Most showed approximately normal or slightly skewed distributions. Categorical features (sex, cp, fbs, restecg, exang, slope, ca, thal, target) were analyzed using count plots, revealing the frequency of each category. The target variable distribution showed a relatively balanced split between the presence (1) and absence (0) of heart disease.
### Bivariate Analysis
Relationships between features and the target variable were explored. Box plots of numerical features against the target showed potential differences in distributions for patients with and without heart disease. Count plots of categorical features against the target revealed how the distribution of each category relates to the target outcome. The correlation matrix heatmap indicated varying degrees of correlation between numerical features and the target. Features like 'thalach', 'oldpeak', 'cp', 'exang', and 'ca' showed notable correlations with the target.

## Data Preprocessing
The raw data underwent the following preprocessing steps:
- **Missing Values:** Checked for missing values; none were found.
- **Outlier Treatment:** Outliers in numerical features ('age', 'trestbps', 'chol', 'thalach', 'oldpeak') were capped at the 1st and 99th percentiles to mitigate their impact.
- **Categorical Encoding:** Categorical features ('sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal') were converted into numerical format using one-hot encoding.
- **Feature Scaling:** Numerical features were scaled using `StandardScaler` to ensure they contribute equally to the models, which is particularly important for distance-based algorithms like KNN and SVM.
- **Data Splitting:** The dataset was split into training (75%) and testing (25%) sets using `train_test_split`, with stratification on the target variable to maintain the proportion of heart disease cases in both sets.

## Model Building and Evaluation
Four classification models were chosen and trained on the preprocessed training data:
- K-Nearest Neighbors (KNN)
- Support Vector Machine (SVM)
- Decision Tree
- Random Forest

Each model was evaluated on the testing data using the following metrics:
- **Accuracy:** Overall correctness of predictions.
- **Precision:** Proportion of positive predictions that were actually correct.
- **Recall:** Proportion of actual positive cases that were correctly identified (minimizing false negatives).
- **F1-score:** Harmonic mean of Precision and Recall.

The evaluation results were as follows:

--- KNN ---
Accuracy: 0.7500
Precision: 0.7619
Recall: 0.7805
F1-score: 0.7711

--- SVM ---
Accuracy: 0.7763
Precision: 0.7727
Recall: 0.8293
F1-score: 0.8000

--- Decision Tree ---
Accuracy: 0.7632
Precision: 0.7447
Recall: 0.8537
F1-score: 0.7955

--- Random Forest ---
Accuracy: 0.7500
Precision: 0.7292
Recall: 0.8537
F1-score: 0.7865

## Model Comparison and Conclusion
In the context of predicting heart disease, **Recall** is the most critical metric, as minimizing false negatives is paramount. Comparing the models based on their Recall scores:
- Decision Tree and Random Forest models achieved the highest Recall (0.8537 and 0.8537, respectively), indicating they were best at identifying individuals with heart disease.
- The SVM model had a slightly lower Recall (0.8293).
- The KNN model had the lowest Recall (0.7805).

While the Decision Tree and Random Forest models showed the strongest performance in terms of Recall, it's important to consider the trade-offs with other metrics. For example, they might have slightly lower Precision compared to models that are more conservative in their positive predictions.

Given the problem's focus on minimizing false negatives, the **Decision Tree** and **Random Forest** models are the most suitable among those evaluated. Further hyperparameter tuning of these models, specifically aimed at maximizing Recall, could potentially lead to even better performance for this critical task.
